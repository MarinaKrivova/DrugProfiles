{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Epsilon-Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import leastsq\n",
    "import scipy.optimize as opt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "from data_preprocessing import FilteringCurves, ShowResponseCurves\n",
    "from fitting_curves import FittingColumn, ShowResponseCurvesWithFitting, compute_r2_score\n",
    "\n",
    "# from IPython.display import display\n",
    "#_FOLDER = \"results/\"\n",
    "_FOLDER = \"/home/acq18mk/master/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Coding Part\n",
    "\n",
    "def LeaveOneOutError(kernel_model, X, y, metrics = \"mse\"):\n",
    "    errors = []\n",
    "    splitter_loo = LeaveOneOut()\n",
    "#     print(splitter_loo.get_n_splits(X))\n",
    "    \n",
    "    for train_index, test_index in splitter_loo.split(X):\n",
    "        X_train_loo, X_test_loo = X[train_index, :], X[test_index,:]\n",
    "        y_train_loo, y_test_loo = y[train_index], y[test_index]\n",
    "        \n",
    "        model = kernel_model.fit(X_train_loo, y_train_loo)\n",
    "        if metrics == \"mse\":\n",
    "            mse = mean_squared_error(y_test_loo, model.predict(X_test_loo))\n",
    "            errors.append(mse)\n",
    "        elif metrics == \"mae\":\n",
    "            mae = mean_absolute_error(y_test_loo, model.predict(X_test_loo))\n",
    "            errors.append(mae)\n",
    "    \n",
    "    return (sum(errors)/ len(errors)) \n",
    "\n",
    "\n",
    "def TrainTestBestParameters(merged_df, drug_ids, number_coefficients, kernels =[], \n",
    "                            column_not_to_use =[], best_parameters_dict={}, \n",
    "                            metrics = \"mse\", features_to_scale=[], \n",
    "                            scaling=False, print_results=True):\n",
    "    tests={}\n",
    "    for kernel in kernels:\n",
    "        if kernel == \"linear\":\n",
    "            tests[\"linear\"] = TestTunedKernels(merged_df, drug_ids, number_coefficients, \n",
    "                                               kernel = kernel, \n",
    "                                               column_not_to_use=column_not_to_use,\n",
    "                                               C = best_parameters_dict[kernel][\"C\"], \n",
    "                                               epsilon =best_parameters_dict[kernel][\"epsilon\"],\n",
    "                                               metrics = \"mse\", \n",
    "                                               features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                               print_results=print_results)\n",
    "        elif kernel == \"poly\":\n",
    "            tests['poly'] = TestTunedKernels(merged_df, drug_ids, number_coefficients, \n",
    "                                             kernel= kernel, \n",
    "                                             column_not_to_use  =column_not_to_use,\n",
    "                                             C = best_parameters_dict[kernel][\"C\"],  \n",
    "                                             degree = best_parameters_dict[kernel][\"degree\"], \n",
    "                                             epsilon = best_parameters_dict[kernel][\"epsilon\"],\n",
    "                                             coef0 = best_parameters_dict[kernel][\"coef0\"],\n",
    "                                             metrics = \"mse\", \n",
    "                                             features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                             print_results=print_results)\n",
    "        else:\n",
    "            tests[kernel] = TestTunedKernels(merged_df, drug_ids, number_coefficients, \n",
    "                                             kernel = kernel, \n",
    "                                             column_not_to_use = column_not_to_use,\n",
    "                                             C = best_parameters_dict[kernel][\"C\"], \n",
    "                                             coef0 = best_parameters_dict[kernel][\"coef0\"],\n",
    "                                             epsilon = best_parameters_dict[kernel][\"epsilon\"],\n",
    "                                             metrics = \"mse\", \n",
    "                                             features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                             print_results = print_results)\n",
    "    best_kernels = {}\n",
    "    coef_names= [\"coef_\"+str(i) for i in range(1, number_coefficients+1)]\n",
    "    compared_means = pd.DataFrame(index=coef_names, columns= kernels)\n",
    "    for i in range(number_coefficients):\n",
    "        test_kernels_comparison = pd.DataFrame(index=[\"mean\", \"min\", \"max\"])\n",
    "        for kernel in kernels:\n",
    "            test_kernels_comparison[kernel] = tests[kernel][tests[kernel].columns[i]]\n",
    "        \n",
    "        compared_means.loc[\"coef_\"+str(i+1), :] = test_kernels_comparison.loc[\"mean\", :]\n",
    "        print(test_kernels_comparison)\n",
    "        best_kernels[i+1]= test_kernels_comparison.loc[\"mean\", :].idxmin(axis=1)\n",
    "        print(\"Coefficient: %d, best kernel: %s\" % (i+1, best_kernels[i+1]))\n",
    "    \n",
    "    return best_kernels, compared_means\n",
    "\n",
    "\n",
    "def RunCrossValidation(merged_df, drug_ids, number_coefficients, train_ratio=0.8, column_not_to_use =[], \n",
    "                       kernel='linear', param_tested = \"C\", param_tested_values = [], \n",
    "                       degree=3, gamma=\"scale\", coef0=0.0, C=1.0, epsilon=0.1, cache_size=200,\n",
    "                       features_to_scale=[], scaling=False, print_results=True):\n",
    "    \n",
    "    param1 = [\"param_\" +str(i) for i in range(10)]\n",
    "    param2 = [\"param\" +str(i) for i in range(10)] \n",
    "    norm_response  = [\"norm_cells_\"+str(i) for i in range(10)]\n",
    "    con_columns  = [\"fd_num_\"+str(i) for i in range(10)]\n",
    "    not_X_columns = param1 + param2 + norm_response + con_columns+column_not_to_use\n",
    "    X_columns = set(merged_df.columns) - set(not_X_columns)\n",
    "    print(\"Number of X_columns:\", len(X_columns))\n",
    "    \n",
    "    df_errors = pd.DataFrame()\n",
    "    #check whether each coefficient needs its own parameters\n",
    "    \n",
    "\n",
    "    for drug_id in drug_ids:\n",
    "        merged_df_i = merged_df[merged_df[\"DRUG_ID\"]==drug_id]\n",
    "        # merged_df_i has lower shape\n",
    "        np.random.seed(123)\n",
    "        indexes = np.random.permutation(merged_df_i.index)\n",
    "        train_size = int(merged_df_i.shape[0]*train_ratio)\n",
    "        indexes_train = indexes[:train_size]\n",
    "        if scaling:\n",
    "            train=merged_df_i.loc[indexes_train, X_columns].copy()\n",
    "            scaler = MinMaxScaler()\n",
    "            train[columns_for_normalisation] = scaler.fit_transform(train[columns_for_normalisation])\n",
    "            X_train = train.values     \n",
    "        else:\n",
    "            X_train = merged_df_i.loc[indexes_train, X_columns].values\n",
    "    \n",
    "        for i in range(number_coefficients):\n",
    "            #check whether each coefficient needs its own parameters\n",
    "            \n",
    "            if type(cache_size)==dict:\n",
    "                cache_size_value = cache_size[i+1]\n",
    "            else:\n",
    "                cache_size_value = cache_size\n",
    "            \n",
    "            if type(epsilon)==dict:\n",
    "                epsilon_value = epsilon[i+1]\n",
    "            else:\n",
    "                epsilon_value = epsilon\n",
    "                \n",
    "            if type(C)==dict:\n",
    "                C_value = C[i+1]\n",
    "            else:\n",
    "                C_value = C\n",
    "                \n",
    "            if type(gamma)==dict:\n",
    "                gamma_value = gamma[i+1]\n",
    "            else:\n",
    "                gamma_value = gamma\n",
    "            \n",
    "            if type(degree)==dict:\n",
    "                degree_value = degree[i+1]\n",
    "            else:\n",
    "                degree_value = degree\n",
    "                \n",
    "            if type(coef0)==dict:\n",
    "                coef0_value = coef0[i+1]\n",
    "            else:\n",
    "                coef0_value = coef0\n",
    "            \n",
    "            y_train = merged_df_i.loc[indexes_train, \"param_\"+str(i+1)].values\n",
    "\n",
    "            for param in param_tested_values:\n",
    "                if param_tested == \"cache_size\":\n",
    "                    kernel_model = SVR(kernel = kernel, \n",
    "                                       cache_size = param, \n",
    "                                       epsilon = epsilon_value,\n",
    "                                       C = C_value,\n",
    "                                       gamma = gamma_value, \n",
    "                                       degree = degree_value, \n",
    "                                       coef0 = coef0_value)\n",
    "                \n",
    "                elif param_tested == \"epsilon\":\n",
    "                    kernel_model = SVR(kernel = kernel, \n",
    "                                       epsilon = param, \n",
    "                                       cache_size=cache_size_value,\n",
    "                                       C = C_value,\n",
    "                                       gamma = gamma_value, \n",
    "                                       degree = degree_value, \n",
    "                                       coef0 = coef0_value)\n",
    "        \n",
    "                elif param_tested == \"C\":\n",
    "                    kernel_model = SVR(kernel = kernel,\n",
    "                                       C = param,\n",
    "                                       epsilon = epsilon_value,\n",
    "                                       cache_size=cache_size_value,\n",
    "                                       gamma = gamma_value, \n",
    "                                       degree = degree_value, \n",
    "                                       coef0 = coef0_value)\n",
    "                    \n",
    "                elif param_tested == \"gamma\":\n",
    "                    kernel_model = SVR(kernel = kernel, \n",
    "                                       C = C_value, \n",
    "                                       epsilon = epsilon_value,\n",
    "                                       cache_size=cache_size_value,\n",
    "                                       gamma = param, \n",
    "                                       degree = degree_value,\n",
    "                                       coef0 = coef0_value)\n",
    "                    \n",
    "                elif param_tested == \"degree\":\n",
    "                    kernel_model = SVR(kernel = kernel, \n",
    "                                       C = C_value,\n",
    "                                       epsilon = epsilon_value,\n",
    "                                       cache_size=cache_size_value,\n",
    "                                       gamma = gamma_value,\n",
    "                                       degree = param, \n",
    "                                       coef0 = coef0_value)\n",
    "                elif param_tested == \"coef0\":\n",
    "                    kernel_model = SVR(kernel = kernel, \n",
    "                                       C = C_value,\n",
    "                                       epsilon = epsilon_value,\n",
    "                                       cache_size=cache_size_value,\n",
    "                                       gamma = gamma_value,\n",
    "                                       degree = degree_value,\n",
    "                                       coef0 = param)\n",
    "                else:\n",
    "                    print(\"ERROR: Unknown parameters\")\n",
    "                \n",
    "                # mse is more sensitive to different parameters choice\n",
    "                mse = LeaveOneOutError(kernel_model, X_train, y_train, metrics=\"mse\")\n",
    "                df_errors.loc[drug_id, \"mse_coef\"+str(i+1)+\"_\"+str(param)] = mse\n",
    "\n",
    "        \n",
    "    best_values = {}\n",
    "    for coef in range(number_coefficients):\n",
    "        df_results = df_errors[[\"mse_coef\"+str(coef+1)+\"_\"+str(param) for param in param_tested_values]].describe().loc[[\"mean\", \"min\",\"max\"], :]\n",
    "        best_param = df_results.loc[\"mean\",:].idxmin().split(\"_\")[-1]\n",
    "#         print(best_param)\n",
    "        if param!= \"gamma\":\n",
    "            best_param = np.float32(best_param)\n",
    "        best_values[coef+1] = best_param\n",
    "        if print_results:\n",
    "            print(df_results)\n",
    "            print(\"Coefficient %d: ,  Best %s: %.5f\" % (coef+1, param_tested, best_param))\n",
    "        \n",
    "    del df_errors\n",
    "    print(\"%s kernel, best values for parameter: %s\" % (kernel, param_tested))\n",
    "    print(best_values)\n",
    "    return best_values\n",
    "\n",
    "def TuneParameters(merged_df, drug_ids, number_coefficients, kernels = [], column_not_to_use =[], \n",
    "                   param_tested = \"C\", param_tested_values = [], \n",
    "                   degree=3, gamma='scale', coef0=0.0, C=1.0, epsilon=0.1, cache_size=200,\n",
    "                   features_to_scale=[], scaling=False, print_results=True):\n",
    "                         \n",
    "    results = {}\n",
    "    for kernel in kernels:\n",
    "        start_time = time.time()\n",
    "        if kernel == \"linear\":\n",
    "#             best_cache_size = RunCrossValidation(merged_df, drug_ids, number_coefficients, \n",
    "#                                             kernel=kernel, \n",
    "#                                             column_not_to_use=column_not_to_use, \n",
    "#                                             param_tested = \"cache_size\", \n",
    "#                                             param_tested_values = [5, 10, 20, 50],\n",
    "#                                             features_to_scale = features_to_scale, scaling = scaling,\n",
    "#                                             print_results=print_results)\n",
    "            \n",
    "            best_epsilon = RunCrossValidation(merged_df, drug_ids, number_coefficients, \n",
    "                                            kernel=kernel, \n",
    "                                            column_not_to_use=column_not_to_use, \n",
    "                                            param_tested = \"epsilon\", \n",
    "                                            param_tested_values = [0.001, 0.01, 0.1, 1, 2, 5],\n",
    "                                            features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                            print_results=print_results)\n",
    "                         \n",
    "            best_C = RunCrossValidation(merged_df, drug_ids, number_coefficients, \n",
    "                                        kernel=kernel, \n",
    "                                        column_not_to_use=column_not_to_use, \n",
    "                                        param_tested = \"C\", \n",
    "                                        param_tested_values = [0.1, 0.5, 1, 5, 7, 10, 30, 50, 100, 200, 300, 500],\n",
    "                                        features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                        epsilon = best_epsilon,\n",
    "                                        print_results=print_results)\n",
    "            \n",
    "            print(\"\\n%s kernel: Execution time: %.3f seconds \\n\" % (kernel, (time.time() - start_time)))\n",
    "            results[kernel]={}\n",
    "            results[kernel][\"epsilon\"] = best_epsilon\n",
    "            results[kernel][\"C\"] = best_C\n",
    "            \n",
    "        elif kernel == \"poly\":\n",
    "            start_time = time.time()\n",
    "#             best_cache_size = RunCrossValidation(merged_df, drug_ids, number_coefficients, \n",
    "#                                             kernel =k ernel, \n",
    "#                                             column_not_to_use = column_not_to_use, \n",
    "#                                             param_tested = \"cache_size\", \n",
    "#                                             param_tested_values = [5, 10, 20, 50],\n",
    "#                                             features_to_scale = features_to_scale, scaling = scaling,\n",
    "#                                             print_results=print_results)\n",
    "            \n",
    "            best_epsilon = RunCrossValidation(merged_df, drug_ids, number_coefficients, \n",
    "                                            kernel = kernel, \n",
    "                                            column_not_to_use = column_not_to_use, \n",
    "                                            param_tested = \"epsilon\", \n",
    "                                            param_tested_values = [0.001, 0.01, 0.1, 1, 2, 5],\n",
    "                                            features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                            print_results=print_results)\n",
    "\n",
    "            best_degree = RunCrossValidation(merged_df, drug_ids, number_coefficients, \n",
    "                                             kernel = kernel, \n",
    "                                             column_not_to_use = column_not_to_use, \n",
    "                                             param_tested = \"degree\", \n",
    "                                             param_tested_values = [1,2,3,4,5], \n",
    "                                             epsilon = best_epsilon,\n",
    "                                             features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                             print_results=print_results)\n",
    "            \n",
    "            best_coef0 = RunCrossValidation(merged_df, drug_ids, number_coefficients, \n",
    "                                            kernel = kernel, \n",
    "                                            column_not_to_use = column_not_to_use, \n",
    "                                            param_tested = \"coef0\", \n",
    "                                            param_tested_values = [-0.1, 0, 0.1, 0.5, 1,  5, 10], \n",
    "                                            epsilon = best_epsilon,\n",
    "                                            degree = best_degree,\n",
    "                                            features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                            print_results=print_results)\n",
    "\n",
    "            best_C = RunCrossValidation(merged_df, drug_ids, number_coefficients, \n",
    "                                        kernel = kernel, \n",
    "                                        column_not_to_use = column_not_to_use, \n",
    "                                        param_tested = \"C\", \n",
    "                                        degree = best_degree,\n",
    "                                        coef0 = best_coef0,\n",
    "                                        param_tested_values = [0.001, 0.01, 0.1, 1, 5, 7], \n",
    "                                        features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                        print_results=print_results)            \n",
    "            \n",
    "                         \n",
    "            print(\"\\n%s kernel: Execution time: %.3f seconds \\n\" % (kernel, (time.time() - start_time)))\n",
    "            results[kernel]={}\n",
    "            results[kernel][\"C\"] = best_C\n",
    "            results[kernel][\"degree\"] = best_degree\n",
    "            results[kernel][\"coef0\"] = best_coef0\n",
    "            results[kernel][\"epsilon\"] = best_epsilon\n",
    "            \n",
    "        else: \n",
    "            start_time = time.time()\n",
    "#             best_cache_size = RunCrossValidation(merged_df, drug_ids, number_coefficients, \n",
    "#                                             kernel =kernel, \n",
    "#                                             column_not_to_use = column_not_to_use, \n",
    "#                                             param_tested = \"cache_size\", \n",
    "#                                             param_tested_values = [5, 10, 20, 50],\n",
    "#                                             features_to_scale = features_to_scale, scaling = scaling,\n",
    "#                                             print_results=print_results\n",
    "            \n",
    "            best_epsilon = RunCrossValidation(merged_df, drug_ids, number_coefficients, \n",
    "                                            kernel = kernel, \n",
    "                                            column_not_to_use = column_not_to_use, \n",
    "                                            param_tested = \"epsilon\", \n",
    "                                            param_tested_values = [0.001, 0.01, 0.1, 1, 2, 5],\n",
    "                                            features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                            print_results=print_results)\n",
    "            \n",
    "            best_coef0 = RunCrossValidation(merged_df, drug_ids, number_coefficients, \n",
    "                                            kernel = kernel, \n",
    "                                            column_not_to_use = column_not_to_use, \n",
    "                                            param_tested = \"coef0\",\n",
    "                                            param_tested_values = [-0.1, 0, 0.1, 0.5, 1,  5, 10], \n",
    "                                            epsilon = best_epsilon,\n",
    "                                            features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                            print_results=print_results)\n",
    "\n",
    "            best_C = RunCrossValidation(merged_df, drug_ids, number_coefficients, \n",
    "                                        kernel = kernel, \n",
    "                                        column_not_to_use = column_not_to_use, \n",
    "                                        param_tested = \"C\", \n",
    "                                        coef0 = best_coef0,\n",
    "                                        param_tested_values = [0.001, 0.01, 0.1, 1, 5, 7], \n",
    "                                        features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                        print_results=print_results)\n",
    "            print(\"\\n%s kernel: Execution time: %.3f seconds \\n\" % (kernel, (time.time() - start_time)))\n",
    "            results[kernel]={}\n",
    "            results[kernel][\"C\"] = best_C\n",
    "            results[kernel][\"coef0\"] = best_coef0\n",
    "            results[kernel][\"epsilon\"] = best_epsilon\n",
    "            \n",
    "    return  results\n",
    "\n",
    "\n",
    "def TestTunedKernels(merged_df, drug_ids, number_coefficients, kernel, train_ratio =0.8, column_not_to_use =[], \n",
    "                     degree=3, gamma='scale', coef0=0.0, C=1.0, epsilon=0.1, cache_size=200,\n",
    "                     metrics = \"mse\", features_to_scale=[], scaling=False, print_results=True):\n",
    "    \"\"\"Training and testing Kernels with the best found hyperparameters\"\"\"\n",
    "    \n",
    "    param1 = [\"param_\" +str(i) for i in range(10)]\n",
    "    param2 = [\"param\" +str(i) for i in range(10)] \n",
    "    norm_response  = [\"norm_cells_\"+str(i) for i in range(10)]\n",
    "    con_columns  = [\"fd_num_\"+str(i) for i in range(10)]\n",
    "\n",
    "    not_X_columns = param1 + param2 + norm_response + con_columns+column_not_to_use\n",
    "    X_columns = set(df.columns) - set(not_X_columns)\n",
    "    print(\"Number of X_columns:\", len(X_columns))\n",
    "    \n",
    "    df_errors_test = pd.DataFrame()\n",
    "\n",
    "    for drug_id in drug_ids:\n",
    "        # merged_df_i has lower shape\n",
    "        merged_df_i = merged_df[merged_df[\"DRUG_ID\"]==drug_id]\n",
    "        \n",
    "        np.random.seed(123)\n",
    "        indexes = np.random.permutation(merged_df_i.index)\n",
    "        train_size = int(merged_df_i.shape[0]*train_ratio)\n",
    "        indexes_train = indexes[:train_size]\n",
    "        indexes_test= indexes[train_size:]\n",
    "        \n",
    "        if scaling:\n",
    "            train = merged_df_i.loc[indexes_train, X_columns].copy()\n",
    "            test = merged_df_i.loc[indexes_test, X_columns].copy()\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(train[columns_for_normalisation])\n",
    "            train[columns_for_normalisation] = scaler.transform(train[columns_for_normalisation])\n",
    "            X_train = train.values  \n",
    "            test[columns_for_normalisation] = scaler.transform(test[columns_for_normalisation])\n",
    "            X_test = test.values\n",
    "        else:\n",
    "            X_train = merged_df_i.loc[indexes_train, X_columns].values\n",
    "            X_test = merged_df_i.loc[indexes_test, X_columns].values\n",
    "    \n",
    "        for i in range(number_coefficients):\n",
    "#             param = best_param[i+1]\n",
    "            y_train = merged_df_i.loc[indexes_train, \"param_\"+str(i+1)].values\n",
    "            y_test = merged_df_i.loc[indexes_test, \"param_\"+str(i+1)].values\n",
    "            \n",
    "            #check whether each coefficient needs its own parameters\n",
    "            if type(cache_size)==dict:\n",
    "                cache_size_value = cache_size[i+1]\n",
    "            else:\n",
    "                cache_size_value = cache_size\n",
    "            \n",
    "            if type(epsilon)==dict:\n",
    "                epsilon_value = epsilon[i+1]\n",
    "            else:\n",
    "                epsilon_value = epsilon\n",
    "                \n",
    "            if type(C)==dict:\n",
    "                C_value = C[i+1]\n",
    "            else:\n",
    "                C_value = C\n",
    "                \n",
    "            if type(gamma)==dict:\n",
    "                gamma_value = gamma[i+1]\n",
    "            else:\n",
    "                gamma_value = gamma\n",
    "            \n",
    "            if type(degree)==dict:\n",
    "                degree_value = degree[i+1]\n",
    "            else:\n",
    "                degree_value = degree\n",
    "                \n",
    "            if type(coef0)==dict:\n",
    "                coef0_value = coef0[i+1]\n",
    "            else:\n",
    "                coef0_value = coef0\n",
    "                \n",
    "            kr_lin = SVR(kernel = kernel, C = C_value,\n",
    "                                       epsilon = epsilon_value,\n",
    "                                       cache_size=cache_size_value,\n",
    "                                       gamma = gamma_value,\n",
    "                                       degree = degree_value, \n",
    "                                       coef0 = coef0_value)\n",
    "            \n",
    "            kr_lin.fit(X_train, y_train)\n",
    "            y_pred = kr_lin.predict(X_test)\n",
    "                                \n",
    "            if metrics == \"mse\":\n",
    "                error = mean_squared_error(y_test, y_pred)\n",
    "            elif metrics == \"mae\":\n",
    "                error = mean_absolute_error(y_test, y_pred)\n",
    "            else:\n",
    "                print(\"ERROR: Unknown metrics\")\n",
    "            df_errors_test.loc[drug_id, kernel+\"_mse_coef\"+str(i+1)] = error\n",
    "    \n",
    "    df_results = df_errors_test.describe().loc[[\"mean\", \"min\",\"max\"], :]\n",
    "    if print_results: \n",
    "        print(df_results)\n",
    "    return df_results\n",
    "\n",
    "\n",
    "### Analytical Part\n",
    "\n",
    "# **Data Preprocessing pipeline:**\n",
    "#     1. filter drug_profiles data \n",
    "#     (123 - three stages of filtration, 23 - two stages of filtration):\n",
    "#         - \"results/filtered_drug_profiles_123\" (less data)\n",
    "#         - \"results/filtered_drug_profiles_23\" (more data)\n",
    "#     2. add drug features to drug data\n",
    "#     - \"data/Drug_Features.csv\" (original data)\n",
    "#     - \"results/drug_features_with_properties2.csv\" (data with pubchem properties)\n",
    "#     3. merged drug_profiles and drug_features\n",
    "# **For goog comparison:**\n",
    "#     filter merged data so that they have only drug with features \n",
    "#     <br>for both data frames (original drug features and with added pubchem features)\n",
    "\n",
    "column_not_to_use = [\"Unnamed: 0\", \"COSMIC_ID\", \"DRUG_ID\", \"Drug_Name\", \"Synonyms\", \"Target\", \n",
    "                     \"deriv_found\", \"PubChem_ID\", \"elements\", \"inchi_key\", \"canonical_smiles\", \n",
    "                     \"inchi_string\", \"molecular_formula\", \"Target\",\n",
    "                     \"third_target\", \"first_target\", \"second_target\", \"Target_Pathway\"]\n",
    "\n",
    "param1 = [\"param_\" +str(i) for i in range(10)]\n",
    "param2 = [\"param\" +str(i) for i in range(10)] \n",
    "norm_response  = [\"norm_cells_\"+str(i) for i in range(10)]\n",
    "\n",
    "### 1. Finding optimal parameters for just drug profiles and cell lines\n",
    "\n",
    "print(\"\\n1. Finding optimal parameters for just drug profiles and cell lines\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_description.csv')\n",
    "\n",
    "conc_columns= [\"fd_num_\"+str(i) for i in range(10)]\n",
    "response_norm = ['norm_cells_'+str(i) for i in range(10)]\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "print(\"Number of drugs for training:\", len(drug_ids))\n",
    "\n",
    "kernels_to_test = [\"linear\", \"sigmoid\", \"poly\", \"rbf\"]\n",
    "results = TuneParameters(df, drug_ids, 4, kernels = kernels_to_test, \n",
    "                         column_not_to_use=column_not_to_use, print_results=False)\n",
    "\n",
    "print(\"Tuned parameters:\")\n",
    "print(results)\n",
    "print(\"\\nBetter presentation:\")\n",
    "for key in results:\n",
    "    print(key,\"\\t\", results[key])\n",
    "\n",
    "best_kernels, compared_means = TrainTestBestParameters(df, drug_ids, 4, kernels = kernels_to_test, \n",
    "                                                       column_not_to_use=column_not_to_use, \n",
    "                                                       best_parameters_dict = results, print_results=True)\n",
    "print(\"Best Kernels:\", best_kernels)\n",
    "compared_means.to_csv(_FOLDER+\"kernel_learning_1_3.csv\")\n",
    "print(\"\\ncompared_means\\n\")\n",
    "print(compared_means)\n",
    "      \n",
    "\n",
    "### 2. Finding optimal parameters for drug profiles, cell lines and drug description\n",
    "\n",
    "print(\"\\n2. Finding optimal parameters for drug profiles, cell lines and drug description\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_description.csv')\n",
    "\n",
    "# OHE and dumnies columns for Target_Pathway - 21 new columns\n",
    "df = pd.concat([df, pd.get_dummies(df[\"Target_Pathway\"])], axis=1)\n",
    "\n",
    "conc_columns= [\"fd_num_\"+str(i) for i in range(10)]\n",
    "response_norm = ['norm_cells_'+str(i) for i in range(10)]\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "print(\"Number of drugs for training:\", len(drug_ids))\n",
    "\n",
    "kernels_to_test = [\"linear\", \"sigmoid\", \"poly\", \"rbf\"]\n",
    "results = TuneParameters(df, drug_ids, 4, kernels = kernels_to_test, \n",
    "                         column_not_to_use=column_not_to_use, print_results=False)\n",
    "\n",
    "print(\"Tuned parameters:\")\n",
    "print(results)\n",
    "print(\"\\nBetter presentation:\")\n",
    "for key in results:\n",
    "    print(key,\"\\t\", results[key])\n",
    "\n",
    "best_kernels, compared_means = TrainTestBestParameters(df, drug_ids, 4, kernels = kernels_to_test, \n",
    "                                                       column_not_to_use=column_not_to_use, \n",
    "                                                       best_parameters_dict = results, print_results=True)\n",
    "print(\"Best Kernels:\", best_kernels)\n",
    "compared_means.to_csv(_FOLDER+\"kernel_learning_2_3.csv\")\n",
    "\n",
    "print(\"\\ncompared_means\\n\")\n",
    "print(compared_means)\n",
    "\n",
    "### 3. Finding optimal parameters for drug profiles, cell lines and drug features\n",
    "\n",
    "print(\"\\n3. Finding optimal parameters for drug profiles, cell lines and drug features\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_properties.csv')\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "print(\"Number of drugs for training:\", len(drug_ids))\n",
    "\n",
    "kernels_to_test = [\"linear\", \"sigmoid\", \"poly\", \"rbf\"]\n",
    "results = TuneParameters(df, drug_ids, 4, kernels = kernels_to_test, \n",
    "                         column_not_to_use=column_not_to_use, print_results=False)\n",
    "\n",
    "print(\"Tuned parameters:\")\n",
    "print(results)\n",
    "print(\"\\nBetter presentation:\")\n",
    "for key in results:\n",
    "    print(key,\"\\t\", results[key])\n",
    "\n",
    "best_kernels, compared_means = TrainTestBestParameters(df, drug_ids, 4, kernels = kernels_to_test, \n",
    "                                                       column_not_to_use=column_not_to_use, \n",
    "                                                       best_parameters_dict = results, print_results=True)\n",
    "print(\"Best Kernels:\", best_kernels)\n",
    "compared_means.to_csv(_FOLDER+\"kernel_learning_3_3.csv\")\n",
    "print(\"\\ncompared_means\\n\")\n",
    "print(compared_means)\n",
    "\n",
    "### 4. Finding optimal parameters for drug profiles, cell lines and drug features with SCALING\n",
    "\n",
    "print(\"\\n4. Finding optimal parameters for drug profiles, cell lines and drug features with scaling\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_properties.csv')\n",
    "\n",
    "potential_columns_for_normalisation = []\n",
    "for col in df.columns:\n",
    "    if (df[col].nunique()>2) & (df[col].dtype != \"O\"):\n",
    "        potential_columns_for_normalisation.append(col)\n",
    "\n",
    "columns_for_normalisation = list(set(potential_columns_for_normalisation) - set(norm_response) - set(param1) - set(param2) -set(['Unnamed: 0', 'DRUG_ID', 'COSMIC_ID',]))\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "print(\"Number of drugs for training:\", len(drug_ids))\n",
    "\n",
    "kernels_to_test = [\"linear\", \"sigmoid\", \"poly\", \"rbf\"]\n",
    "results = TuneParameters(df, drug_ids, 4, kernels = kernels_to_test, column_not_to_use=column_not_to_use, \n",
    "                         features_to_scale=columns_for_normalisation, scaling = True,\n",
    "                         print_results=False)\n",
    "\n",
    "print(\"Tuned parameters:\")\n",
    "print(results)\n",
    "print(\"\\nBetter presentation:\")\n",
    "for key in results:\n",
    "    print(key,\"\\t\", results[key])\n",
    "\n",
    "best_kernels, compared_means = TrainTestBestParameters(df, drug_ids, 4, kernels = kernels_to_test, \n",
    "                                                       column_not_to_use=column_not_to_use, \n",
    "                                                       best_parameters_dict = results, \n",
    "                                                       features_to_scale=columns_for_normalisation, scaling = True,\n",
    "                                                       print_results=True)\n",
    "print(\"Best Kernels:\", best_kernels)\n",
    "compared_means.to_csv(_FOLDER+\"kernel_learning_4_3.csv\")\n",
    "print(\"\\ncompared_means\\n\")\n",
    "print(compared_means)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:jupyter-spark]",
   "language": "python",
   "name": "conda-env-jupyter-spark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
