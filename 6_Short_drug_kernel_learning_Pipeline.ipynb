{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of drugs with more than 50 records: 11\n",
      "Maid train and test sets: (683, 1100) (300, 1100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse_param_1</th>\n",
       "      <th>mae_param_1</th>\n",
       "      <th>mse_param_2</th>\n",
       "      <th>mae_param_2</th>\n",
       "      <th>mse_param_3</th>\n",
       "      <th>mae_param_3</th>\n",
       "      <th>mse_param_4</th>\n",
       "      <th>mae_param_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.904070</td>\n",
       "      <td>0.678699</td>\n",
       "      <td>6.018416</td>\n",
       "      <td>0.894316</td>\n",
       "      <td>591.589625</td>\n",
       "      <td>14.209816</td>\n",
       "      <td>0.030484</td>\n",
       "      <td>0.089112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.695010</td>\n",
       "      <td>0.697080</td>\n",
       "      <td>9.992729</td>\n",
       "      <td>0.896737</td>\n",
       "      <td>664.961714</td>\n",
       "      <td>8.015762</td>\n",
       "      <td>0.057176</td>\n",
       "      <td>0.033918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.021081</td>\n",
       "      <td>0.113052</td>\n",
       "      <td>0.093379</td>\n",
       "      <td>0.236605</td>\n",
       "      <td>66.275078</td>\n",
       "      <td>6.748200</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>0.029845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.055201</td>\n",
       "      <td>0.194046</td>\n",
       "      <td>0.249604</td>\n",
       "      <td>0.408432</td>\n",
       "      <td>115.489903</td>\n",
       "      <td>8.511401</td>\n",
       "      <td>0.009314</td>\n",
       "      <td>0.065713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.935599</td>\n",
       "      <td>0.546047</td>\n",
       "      <td>0.476037</td>\n",
       "      <td>0.534229</td>\n",
       "      <td>360.710725</td>\n",
       "      <td>11.234837</td>\n",
       "      <td>0.013485</td>\n",
       "      <td>0.090251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.005612</td>\n",
       "      <td>0.741883</td>\n",
       "      <td>8.446279</td>\n",
       "      <td>0.967509</td>\n",
       "      <td>788.979109</td>\n",
       "      <td>17.781224</td>\n",
       "      <td>0.019686</td>\n",
       "      <td>0.110931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.729717</td>\n",
       "      <td>2.561256</td>\n",
       "      <td>31.784409</td>\n",
       "      <td>3.344451</td>\n",
       "      <td>1941.714281</td>\n",
       "      <td>33.002168</td>\n",
       "      <td>0.201778</td>\n",
       "      <td>0.144722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mse_param_1  mae_param_1  mse_param_2  mae_param_2  mse_param_3  \\\n",
       "count    11.000000    11.000000    11.000000    11.000000    11.000000   \n",
       "mean      2.904070     0.678699     6.018416     0.894316   591.589625   \n",
       "std       4.695010     0.697080     9.992729     0.896737   664.961714   \n",
       "min       0.021081     0.113052     0.093379     0.236605    66.275078   \n",
       "25%       0.055201     0.194046     0.249604     0.408432   115.489903   \n",
       "50%       0.935599     0.546047     0.476037     0.534229   360.710725   \n",
       "75%       3.005612     0.741883     8.446279     0.967509   788.979109   \n",
       "max      14.729717     2.561256    31.784409     3.344451  1941.714281   \n",
       "\n",
       "       mae_param_3  mse_param_4  mae_param_4  \n",
       "count    11.000000    11.000000    11.000000  \n",
       "mean     14.209816     0.030484     0.089112  \n",
       "std       8.015762     0.057176     0.033918  \n",
       "min       6.748200     0.003616     0.029845  \n",
       "25%       8.511401     0.009314     0.065713  \n",
       "50%      11.234837     0.013485     0.090251  \n",
       "75%      17.781224     0.019686     0.110931  \n",
       "max      33.002168     0.201778     0.144722  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import leastsq\n",
    "import scipy.optimize as opt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import os\n",
    "from data_preprocessing import FilteringCurves, ShowResponseCurves\n",
    "from fitting_curves import FittingColumn, ShowResponseCurvesWithFitting, compute_r2_score\n",
    "_FOLDER = \"./data/\"\n",
    "\n",
    "# NEED TO CHANGE - what file to read\n",
    "df = pd.read_csv(\"./results/merged_drug_profiles_sigmoid4_123.csv\")\n",
    "df.shape\n",
    "\n",
    "conc_columns= [\"fd_num_\"+str(i) for i in range(10)]\n",
    "response_norm = ['norm_cells_'+str(i) for i in range(10)]\n",
    "\n",
    "### Training and testing tuned kernels\n",
    "\n",
    "# select subsets for each drug and divide each of them into train and test data\n",
    "# concatenate all the train and test subsets\n",
    "min_records = 50\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "good_drug_ids = gr[gr>min_records].index\n",
    "print(\"Number of drugs with more than %d records: %d\" % (min_records, len(good_drug_ids)))\n",
    "\n",
    "# making train and test sets\n",
    "train = pd.DataFrame(columns=df.columns)\n",
    "test = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "for drug_id in good_drug_ids:\n",
    "    df_i = df[df[\"DRUG_ID\"]==drug_id]\n",
    "    np.random.seed(123)\n",
    "    indexes = np.random.permutation(df_i.index)\n",
    "    train_size = int(df_i.shape[0]*0.7)\n",
    "    indexes_train = indexes[:train_size]\n",
    "    indexes_test= indexes[train_size:]\n",
    "    \n",
    "    train_set = df_i.loc[indexes_train, :]\n",
    "    test_set = df_i.loc[indexes_test, :]\n",
    "    \n",
    "    train = pd.concat([train, train_set], axis=0)\n",
    "    test = pd.concat([test, test_set], axis=0)\n",
    "    \n",
    "print(\"Maid train and test sets:\", train.shape, test.shape)\n",
    "\n",
    "# training and testing\n",
    "\n",
    "df_errors = pd.DataFrame()\n",
    "df_errors[\"DRUG_ID\"] = good_drug_ids\n",
    "df_errors.set_index(\"DRUG_ID\", inplace =True)\n",
    "\n",
    "test_columns_to_use = ['COSMIC_ID', 'DRUG_ID']+conc_columns+response_norm+[\"param_\"+str(i)for i in range(1,5)]\n",
    "short_test = test[test_columns_to_use].copy()\n",
    "\n",
    "for drug_id in df_errors.index:\n",
    "    \n",
    "    train_i = train[train[\"DRUG_ID\"]==drug_id]\n",
    "    test_i = test[test[\"DRUG_ID\"]==drug_id]\n",
    "\n",
    "    X_train = train_i[train_i.columns[26:-4]].values\n",
    "    X_test = test_i[test_i.columns[26:-4]].values\n",
    "\n",
    "    for i in range(4):\n",
    "        y_train = train_i[\"param_\"+str(i+1)]\n",
    "        y_test = test_i[\"param_\"+str(i+1)]\n",
    "        \n",
    "        # train kernels with best parameters\n",
    "        # @ TO CHANGE !!!\n",
    "        kr_lin = KernelRidge(kernel='linear')\n",
    "        kr_lin.fit(X_train, y_train)\n",
    "        y_pred = kr_lin.predict(X_test)\n",
    "        \n",
    "        # collect errors\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        df_errors.loc[drug_id, \"mse_param_\"+str(i+1)] = mse\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        df_errors.loc[drug_id, \"mae_param_\"+str(i+1)] = mae\n",
    "        \n",
    "        # show on graph fitted and predicted curves\n",
    "        # not all the data was merged=learnd by the model\n",
    "        short_test.loc[test_i.index, \"pred_param_\"+str(i+1)] = kr_lin.predict(X_test)\n",
    "#         print(merged_df.loc[merged_df_i.index, \"pred_param_\"+str(i+1)])\n",
    "\n",
    "# Analysis of the results\n",
    "fitting_cols =[\"param_\"+str(i) for i in range(1,5)]\n",
    "pred_fitting_cols = [\"pred_param_\"+str(i) for i in range(1,5)]\n",
    "fitting_function=\"sigmoid_4_param\"\n",
    "\n",
    "short_test[\"r2_fitted\"] = compute_r2_score(short_test, x_columns = conc_columns, y_columns = response_norm, \n",
    "                              fitting_parameters=fitting_cols, fitting_function = fitting_function)\n",
    "short_test[\"r2_predicted\"] = compute_r2_score(short_test, x_columns = conc_columns, y_columns = response_norm, \n",
    "                              fitting_parameters=pred_fitting_cols, fitting_function = fitting_function)\n",
    "df_errors.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myspark",
   "language": "python",
   "name": "myspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
