{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import leastsq\n",
    "import scipy.optimize as opt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from data_preprocessing import FilteringCurves, ShowResponseCurves\n",
    "from fitting_curves import FittingColumn, ShowResponseCurvesWithFitting, compute_r2_score\n",
    "\n",
    "# from IPython.display import display\n",
    "_FOLDER = \"results/\"\n",
    "# _FOLDER = \"/home/acq18mk/master/results/\"\n",
    "\n",
    "### Coding Part\n",
    "\n",
    "def LeaveOneOutError(kernel_model, X, y, metrics = \"mse\"):\n",
    "    errors = []\n",
    "    splitter_loo = LeaveOneOut()\n",
    "#     print(splitter_loo.get_n_splits(X))\n",
    "    \n",
    "    for train_index, test_index in splitter_loo.split(X):\n",
    "        X_train_loo, X_test_loo = X[train_index, :], X[test_index,:]\n",
    "        y_train_loo, y_test_loo = y[train_index], y[test_index]\n",
    "        \n",
    "        model = kernel_model.fit(X_train_loo, y_train_loo)\n",
    "        if metrics == \"mse\":\n",
    "            mse = mean_squared_error(y_test_loo, model.predict(X_test_loo))\n",
    "            errors.append(mse)\n",
    "        elif metrics == \"mae\":\n",
    "            mae = mean_absolute_error(y_test_loo, model.predict(X_test_loo))\n",
    "            errors.append(mae)\n",
    "    \n",
    "    return (sum(errors)/ len(errors)) \n",
    "\n",
    "# gamma for RBF, laplacian, polynomial, exponential chi2 and sigmoid kernels\n",
    "\n",
    "def RunCrossValidation(merged_df, drug_ids, number_coefficients, train_ratio=0.8, column_not_to_use =[], kernel='linear', param_tested = \"alpha\", \n",
    "                       param_tested_values = [], alpha=1, gamma=None, degree=3, coef0=1,features_to_scale=[], scaling=False, \n",
    "                      print_results=True):\n",
    "    \n",
    "    param1 = [\"param_\" +str(i) for i in range(10)]\n",
    "    param2 = [\"param\" +str(i) for i in range(10)] \n",
    "    norm_response  = [\"norm_cells_\"+str(i) for i in range(10)]\n",
    "    con_columns  = [\"fd_num_\"+str(i) for i in range(10)]\n",
    "    not_X_columns = param1 + param2 + norm_response + con_columns+column_not_to_use\n",
    "    X_columns = set(df.columns) - set(not_X_columns)\n",
    "    print(\"Number of X_columns:\", len(X_columns))\n",
    "    \n",
    "    df_errors = pd.DataFrame()\n",
    "    #check whether each coefficient needs its own parameters\n",
    "    \n",
    "\n",
    "    for drug_id in drug_ids:\n",
    "        merged_df_i = merged_df[merged_df[\"DRUG_ID\"]==drug_id]\n",
    "        # merged_df_i has lower shape\n",
    "        np.random.seed(123)\n",
    "        indexes = np.random.permutation(merged_df_i.index)\n",
    "        train_size = int(merged_df_i.shape[0]*train_ratio)\n",
    "        indexes_train = indexes[:train_size]\n",
    "        if scaling:\n",
    "            train=merged_df_i.loc[indexes_train, X_columns].copy()\n",
    "            scaler = StandardScaler()\n",
    "            train[columns_for_normalisation] = scaler.fit_transform(train[columns_for_normalisation])\n",
    "            X_train = train.values     \n",
    "        else:\n",
    "            X_train = merged_df_i.loc[indexes_train, X_columns].values\n",
    "    \n",
    "        for i in range(number_coefficients):\n",
    "            #check whether each coefficient needs its own parameters\n",
    "            if type(alpha)==dict:\n",
    "                alpha_value = alpha[i+1]\n",
    "            else:\n",
    "                alpha_value = alpha\n",
    "                \n",
    "            if type(gamma)==dict:\n",
    "                gamma_value = gamma[i+1]\n",
    "            else:\n",
    "                gamma_value = gamma\n",
    "            \n",
    "            if type(degree)==dict:\n",
    "                degree_value = degree[i+1]\n",
    "            else:\n",
    "                degree_value = degree\n",
    "                \n",
    "            if type(coef0)==dict:\n",
    "                coef0_value = coef0[i+1]\n",
    "            else:\n",
    "                coef0_value = coef0\n",
    "            \n",
    "            y_train = merged_df_i.loc[indexes_train, \"param_\"+str(i+1)].values\n",
    "\n",
    "            for param in param_tested_values:\n",
    "    \n",
    "                #check whether each coefficient needs its own parameters\n",
    "                if param_tested == \"alpha\":\n",
    "                    kernel_model = KernelRidge(kernel=kernel, \n",
    "                                               alpha=param, \n",
    "                                               gamma=gamma_value, \n",
    "                                               degree=degree_value, \n",
    "                                               coef0=coef0_value)\n",
    "                elif param_tested == \"gamma\":\n",
    "                    kernel_model = KernelRidge(kernel=kernel, \n",
    "                                               alpha=alpha_value, \n",
    "                                               gamma=param, \n",
    "                                               degree=degree_value,\n",
    "                                               coef0=coef0_value)\n",
    "                elif param_tested == \"degree\":\n",
    "                    kernel_model = KernelRidge(kernel=kernel, \n",
    "                                               alpha=alpha_value, \n",
    "                                               gamma=gamma_value,\n",
    "                                               degree=param, \n",
    "                                               coef0=coef0_value)\n",
    "                elif param_tested == \"coef0\":\n",
    "                    kernel_model = KernelRidge(kernel=kernel, \n",
    "                                               alpha=alpha_value,  \n",
    "                                               gamma=gamma_value,\n",
    "                                               degree=degree_value,\n",
    "                                               coef0=param)\n",
    "                else:\n",
    "                    print(\"ERROR: Unknown parameters\")\n",
    "                \n",
    "                # mse is more sensitive to different parameters choice\n",
    "                mse = LeaveOneOutError(kernel_model, X_train, y_train, metrics=\"mse\")\n",
    "                df_errors.loc[drug_id, \"mse_coef\"+str(i+1)+\"_\"+str(param)] = mse\n",
    "\n",
    "        \n",
    "    best_values = {}\n",
    "    for coef in range(number_coefficients):\n",
    "        df_results = df_errors[[\"mse_coef\"+str(coef+1)+\"_\"+str(param) for param in param_tested_values]].describe().loc[[\"mean\", \"min\",\"max\"], :]\n",
    "        best_param = np.float32(df_results.loc[\"mean\",:].idxmin().split(\"_\")[-1])\n",
    "        best_values[coef+1] = best_param\n",
    "        if print_results:\n",
    "            print(df_results)\n",
    "            print(\"Coefficient %d: ,  Best %s: %.5f\" % (coef+1, param_tested, best_param))\n",
    "        \n",
    "    del df_errors\n",
    "    print(\"%s kernel, best values for parameter: %s\" % (kernel, param_tested))\n",
    "    print(best_values)\n",
    "    return best_values\n",
    "\n",
    "def TestTunedKernels(merged_df, drug_ids, number_coefficients, kernel, train_ratio =0.8, column_not_to_use =[], alpha=1, gamma=None, degree=3, coef0=1, \n",
    "                     metrics = \"mse\", features_to_scale=[], scaling=False, print_results=True):\n",
    "    \"\"\"Training and testing Kernels with the best found hyperparameters\"\"\"\n",
    "    \n",
    "    param1 = [\"param_\" +str(i) for i in range(10)]\n",
    "    param2 = [\"param\" +str(i) for i in range(10)] \n",
    "    norm_response  = [\"norm_cells_\"+str(i) for i in range(10)]\n",
    "    con_columns  = [\"fd_num_\"+str(i) for i in range(10)]\n",
    "\n",
    "    not_X_columns = param1 + param2 + norm_response + con_columns+column_not_to_use\n",
    "    X_columns = set(df.columns) - set(not_X_columns)\n",
    "    print(\"Number of X_columns:\", len(X_columns))\n",
    "    \n",
    "    df_errors_test = pd.DataFrame()\n",
    "\n",
    "    for drug_id in drug_ids:\n",
    "        # merged_df_i has lower shape\n",
    "        merged_df_i = merged_df[merged_df[\"DRUG_ID\"]==drug_id]\n",
    "        \n",
    "        np.random.seed(123)\n",
    "        indexes = np.random.permutation(merged_df_i.index)\n",
    "        train_size = int(merged_df_i.shape[0]*train_ratio)\n",
    "        indexes_train = indexes[:train_size]\n",
    "        indexes_test= indexes[train_size:]\n",
    "        \n",
    "        if scaling:\n",
    "            train = merged_df_i.loc[indexes_train, X_columns].copy()\n",
    "            test = merged_df_i.loc[indexes_test, X_columns].copy()\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(train[columns_for_normalisation])\n",
    "            train[columns_for_normalisation] = scaler.transform(train[columns_for_normalisation])\n",
    "            X_train = train.values  \n",
    "            test[columns_for_normalisation] = scaler.transform(test[columns_for_normalisation])\n",
    "            X_test = test.values\n",
    "        else:\n",
    "            X_train = merged_df_i.loc[indexes_train, X_columns].values\n",
    "            X_test = merged_df_i.loc[indexes_test, X_columns].values\n",
    "    \n",
    "        for i in range(number_coefficients):\n",
    "#             param = best_param[i+1]\n",
    "            y_train = merged_df_i.loc[indexes_train, \"param_\"+str(i+1)].values\n",
    "            y_test = merged_df_i.loc[indexes_test, \"param_\"+str(i+1)].values\n",
    "            \n",
    "            #check whether each coefficient needs its own parameters\n",
    "            if type(alpha)==dict:\n",
    "                alpha_value = alpha[i+1]\n",
    "            else:\n",
    "                alpha_value = alpha\n",
    "                \n",
    "            if type(gamma)==dict:\n",
    "                gamma_value = gamma[i+1]\n",
    "            else:\n",
    "                gamma_value = gamma\n",
    "            \n",
    "            if type(degree)==dict:\n",
    "                degree_value = degree[i+1]\n",
    "            else:\n",
    "                degree_value = degree\n",
    "                \n",
    "            if type(coef0)==dict:\n",
    "                coef0_value = coef0[i+1]\n",
    "            else:\n",
    "                coef0_value = coef0\n",
    "                \n",
    "            kr_lin = KernelRidge(kernel = kernel, alpha = alpha_value, gamma=gamma_value, \n",
    "                                 degree=degree_value, coef0=coef0_value)\n",
    "            kr_lin.fit(X_train, y_train)\n",
    "            y_pred = np.exp(kr_lin.predict(X_test))\n",
    "                                \n",
    "            # mse is more sensitive to different parameters choice\n",
    "            if metrics == \"mse\":\n",
    "                error = mean_squared_error(y_test, y_pred)\n",
    "            elif metrics == \"mae\":\n",
    "                error = mean_absolute_error(y_test, y_pred)\n",
    "            else:\n",
    "                print(\"ERROR: Unknown metrics\")\n",
    "            df_errors_test.loc[drug_id, kernel+\"_mse_coef\"+str(i+1)] = error\n",
    "    \n",
    "    df_results = df_errors_test.describe().loc[[\"mean\", \"min\",\"max\"], :]\n",
    "    if print_results: \n",
    "        print(df_results)\n",
    "    return df_results\n",
    "\n",
    "\n",
    "def TuneParameters(merged_df, drug_ids, number_coefficients, kernels = [], column_not_to_use =[], param_tested = \"alpha\", \n",
    "                       param_tested_values = [], alpha=1, gamma=None, degree=3, coef0=1, features_to_scale=[], scaling=False, \n",
    "                      print_results=True):\n",
    "    results = {}\n",
    "    for kernel in kernels:\n",
    "        start_time = time.time()\n",
    "        if kernel == \"linear\":\n",
    "            best_alpha = RunCrossValidation(merged_df, drug_ids, 4, kernel=kernel, column_not_to_use=column_not_to_use, \n",
    "                                            param_tested = \"alpha\", param_tested_values = [0.1, 0.5, 1, 5, 7, 10, 30, 50, 100, 200, 300, 500],\n",
    "                                            features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                            print_results=print_results)\n",
    "            \n",
    "            print(\"\\n%s kernel: Execution time: %.3f seconds \\n\" % (kernel, (time.time() - start_time)))\n",
    "            results[kernel]={}\n",
    "            results[kernel][\"alpha\"] = best_alpha\n",
    "            \n",
    "        elif kernel == \"polynomial\":\n",
    "            start_time = time.time()\n",
    "            best_gamma = RunCrossValidation(merged_df, drug_ids, 4, kernel='polynomial', column_not_to_use=column_not_to_use, param_tested = \"gamma\", \n",
    "                                            param_tested_values = [0.00001, 0.0001, 0.01, 0.1, 1], \n",
    "                                            features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                            print_results=print_results)\n",
    "\n",
    "            best_degree = RunCrossValidation(merged_df, drug_ids, 4, kernel='polynomial', column_not_to_use=column_not_to_use, param_tested = \"degree\", \n",
    "                                             gamma= best_gamma, param_tested_values = [1,2,3,4,5], \n",
    "                                             features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                             print_results=print_results)\n",
    "\n",
    "            best_alpha = RunCrossValidation(merged_df, drug_ids, 4, kernel='polynomial', column_not_to_use=column_not_to_use, param_tested = \"alpha\", \n",
    "                                            gamma= best_gamma, degree = best_degree,\n",
    "                                            param_tested_values = [0.001, 0.01, 0.1, 1, 5, 7], \n",
    "                                            features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                            print_results=print_results)            \n",
    "            \n",
    "            print(\"\\n%s kernel: Execution time: %.3f seconds \\n\" % (kernel, (time.time() - start_time)))\n",
    "            results[kernel]={}\n",
    "            results[kernel][\"alpha\"] = best_alpha\n",
    "            results[kernel][\"gamma\"] = best_gamma\n",
    "            results[kernel][\"degree\"] = best_degree\n",
    "            \n",
    "        else: \n",
    "            start_time = time.time()\n",
    "            best_gamma = RunCrossValidation(merged_df, drug_ids, 4, kernel = kernel, column_not_to_use=column_not_to_use, param_tested = \"gamma\", \n",
    "                                            param_tested_values = [0.00001, 0.0001, 0.01, 0.1, 0.5, 1], \n",
    "                                            features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                            print_results=print_results)\n",
    "\n",
    "            \n",
    "            best_alpha = RunCrossValidation(merged_df, drug_ids, 4, kernel=kernel, column_not_to_use=column_not_to_use, param_tested = \"alpha\", \n",
    "                                            param_tested_values = [0.1, 0.5, 1, 5, 7, 10, 30, 50, 100, 200, 300, 500], \n",
    "                                            features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                            print_results=print_results)\n",
    "            \n",
    "            best_coef0 = RunCrossValidation(merged_df, drug_ids, 4, kernel=kernel, column_not_to_use=column_not_to_use, gamma= best_gamma, \n",
    "                                            param_tested = \"coef0\", alpha=best_alpha,\n",
    "                                            param_tested_values = [-0.1, 0, 0.1, 0.5, 1,  5, 10], \n",
    "                                            features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                            print_results=print_results)\n",
    "\n",
    "            print(\"\\n%s kernel: Execution time: %.3f seconds \\n\" % (kernel, (time.time() - start_time)))\n",
    "            results[kernel]={}\n",
    "            results[kernel][\"alpha\"] = best_alpha\n",
    "            results[kernel][\"gamma\"] = best_gamma\n",
    "            results[kernel][\"coef0\"] = best_coef0\n",
    "            \n",
    "    return  results\n",
    "\n",
    "def TrainTestBestParameters(merged_df, drug_ids, number_coefficients, kernels =[], column_not_to_use =[], best_parameters_dict={}, \n",
    "                     metrics = \"mse\", features_to_scale=[], scaling=False, print_results=True):\n",
    "    tests={}\n",
    "    for kernel in kernels:\n",
    "        if kernel == \"linear\":\n",
    "            tests[\"linear\"] = TestTunedKernels(merged_df, drug_ids, 4, kernel='linear', column_not_to_use=column_not_to_use,\n",
    "                                               alpha=best_parameters_dict[kernel][\"alpha\"], \n",
    "                                               metrics = \"mse\", \n",
    "                                               features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                               print_results=print_results)\n",
    "        elif kernel == \"polynomial\":\n",
    "            tests['polynomial'] = TestTunedKernels(merged_df, drug_ids, 4, kernel='polynomial', column_not_to_use=column_not_to_use,\n",
    "                                                   alpha=best_parameters_dict[kernel][\"alpha\"], \n",
    "                                                   gamma= best_parameters_dict[kernel][\"gamma\"], \n",
    "                                                   degree=best_parameters_dict[kernel][\"degree\"], \n",
    "                                                   metrics = \"mse\", \n",
    "                                                   features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                                   print_results=print_results)\n",
    "        else:\n",
    "            tests[kernel] = TestTunedKernels(merged_df, drug_ids, 4, kernel=kernel, column_not_to_use=column_not_to_use,\n",
    "                                             alpha=best_parameters_dict[kernel][\"alpha\"], \n",
    "                                             gamma= best_parameters_dict[kernel][\"gamma\"],\n",
    "                                             coef0= best_parameters_dict[kernel][\"coef0\"],\n",
    "                                             degree=1, metrics = \"mse\", \n",
    "                                             features_to_scale = features_to_scale, scaling = scaling,\n",
    "                                             print_results=print_results)\n",
    "    best_kernels = {}\n",
    "    coef_names= [\"coef_\"+str(i) for i in range(1, number_coefficients+1)]\n",
    "    compared_means = pd.DataFrame(index=coef_names, columns= kernels)\n",
    "    for i in range(number_coefficients):\n",
    "        test_kernels_comparison = pd.DataFrame(index=[\"mean\", \"min\", \"max\"])\n",
    "        for kernel in kernels:\n",
    "            test_kernels_comparison[kernel] = tests[kernel][tests[kernel].columns[i]]\n",
    "        \n",
    "        compared_means.loc[\"coef_\"+str(i+1), :] = test_kernels_comparison.loc[\"mean\", :]\n",
    "        print(test_kernels_comparison)\n",
    "        best_kernels[i+1]= test_kernels_comparison.loc[\"mean\", :].idxmin(axis=1)\n",
    "        print(\"Coefficient: %d, best kernel: %s\" % (i+1, best_kernels[i+1]))\n",
    "    \n",
    "    return best_kernels, compared_means\n",
    "\n",
    "### Analytical Part\n",
    "\n",
    "# **Data Preprocessing pipeline:**\n",
    "#     1. filter drug_profiles data \n",
    "#     (123 - three stages of filtration, 23 - two stages of filtration):\n",
    "#         - \"results/filtered_drug_profiles_123\" (less data)\n",
    "#         - \"results/filtered_drug_profiles_23\" (more data)\n",
    "#     2. add drug features to drug data\n",
    "#     - \"data/Drug_Features.csv\" (original data)\n",
    "#     - \"results/drug_features_with_properties2.csv\" (data with pubchem properties)\n",
    "#     3. merged drug_profiles and drug_features\n",
    "# **For goog comparison:**\n",
    "#     filter merged data so that they have only drug with features \n",
    "#     <br>for both data frames (original drug features and with added pubchem features)\n",
    "\n",
    "column_not_to_use = [\"Unnamed: 0\", \"COSMIC_ID\", \"DRUG_ID\", \"Drug_Name\", \"Synonyms\", \"Target\", \"deriv_found\", \"PubChem_ID\",\n",
    "                     \"elements\", \"inchi_key\", \"canonical_smiles\", \"inchi_string\", \"third_target\", \"first_target\", \"molecular_formula\", \"second_target\", \"Target_Pathway\"]\n",
    "\n",
    "param1 = [\"param_\" +str(i) for i in range(10)]\n",
    "param2 = [\"param\" +str(i) for i in range(10)] \n",
    "norm_response  = [\"norm_cells_\"+str(i) for i in range(10)]\n",
    "\n",
    "### Finding optimal parameters for just drug profiles and cell lines\n",
    "\n",
    "print(\"\\nFinding optimal parameters for just drug profiles and cell lines\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_description.csv').drop([\"Drug_Name\",\"Target_Pathway\"], axis=1)\n",
    "\n",
    "conc_columns= [\"fd_num_\"+str(i) for i in range(10)]\n",
    "response_norm = ['norm_cells_'+str(i) for i in range(10)]\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "print(\"Number of drugs for training:\", len(drug_ids))\n",
    "\n",
    "kernels_to_test = [\"linear\", \"sigmoid\", \"rbf\", \"polynomial\", \"additive_chi2\", \"laplacian\"]\n",
    "results = TuneParameters(df, drug_ids, 4, kernels = kernels_to_test, column_not_to_use=column_not_to_use, print_results=False)\n",
    "\n",
    "print(\"Tuned parameters:\")\n",
    "print(results)\n",
    "print(\"\\nBetter presentation:\")\n",
    "for key in results:\n",
    "    print(key,\"\\t\", results[key])\n",
    "\n",
    "best_kernels, compared_means = TrainTestBestParameters(df, drug_ids, 4, kernels = kernels_to_test, column_not_to_use=column_not_to_use, best_parameters_dict = results, print_results=True)\n",
    "print(\"Best Kernels:\", best_kernels)\n",
    "compared_means.to_csv(_FOLDER+\"kernel_learning_1.csv\")\n",
    "\n",
    "### Finding optimal parameters for drug profiles, cell lines and drug description\n",
    "\n",
    "print(\"\\nFinding optimal parameters for drug profiles, cell lines and drug description\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_description.csv')\n",
    "\n",
    "# OHE and dumnies columns for Target_Pathway - 21 new columns\n",
    "df = pd.concat([df, pd.get_dummies(df[\"Target_Pathway\"])], axis=1).drop(\"Target_Pathway\", axis=1)\n",
    "\n",
    "conc_columns= [\"fd_num_\"+str(i) for i in range(10)]\n",
    "response_norm = ['norm_cells_'+str(i) for i in range(10)]\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "print(\"Number of drugs for training:\", len(drug_ids))\n",
    "\n",
    "kernels_to_test = [\"linear\", \"sigmoid\", \"rbf\", \"polynomial\", \"additive_chi2\", \"laplacian\"]\n",
    "results = TuneParameters(df, drug_ids, 4, kernels = kernels_to_test, column_not_to_use=column_not_to_use, print_results=False)\n",
    "\n",
    "print(\"Tuned parameters:\")\n",
    "print(results)\n",
    "print(\"\\nBetter presentation:\")\n",
    "for key in results:\n",
    "    print(key,\"\\t\", results[key])\n",
    "\n",
    "best_kernels, compared_means = TrainTestBestParameters(df, drug_ids, 4, kernels = kernels_to_test, column_not_to_use=column_not_to_use, best_parameters_dict = results, print_results=True)\n",
    "print(\"Best Kernels:\", best_kernels)\n",
    "compared_means.to_csv(_FOLDER+\"kernel_learning_2.csv\")\n",
    "\n",
    "### Finding optimal parameters for drug profiles, cell lines and drug features\n",
    "\n",
    "print(\"\\nFinding optimal parameters for drug profiles, cell lines and drug features\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_properties.csv')\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "print(\"Number of drugs for training:\", len(drug_ids))\n",
    "\n",
    "kernels_to_test = [\"linear\", \"sigmoid\", \"rbf\", \"polynomial\", \"additive_chi2\", \"laplacian\"]\n",
    "results = TuneParameters(df, drug_ids, 4, kernels = kernels_to_test, column_not_to_use=column_not_to_use, print_results=False)\n",
    "\n",
    "print(\"Tuned parameters:\")\n",
    "print(results)\n",
    "print(\"\\nBetter presentation:\")\n",
    "for key in results:\n",
    "    print(key,\"\\t\", results[key])\n",
    "\n",
    "best_kernels, compared_means = TrainTestBestParameters(df, drug_ids, 4, kernels = kernels_to_test, column_not_to_use=column_not_to_use, best_parameters_dict = results, print_results=True)\n",
    "print(\"Best Kernels:\", best_kernels)\n",
    "compared_means.to_csv(_FOLDER+\"kernel_learning_3.csv\")\n",
    "\n",
    "### Finding optimal parameters for drug profiles, cell lines and drug features with SCALING\n",
    "\n",
    "print(\"\\nFinding optimal parameters for drug profiles, cell lines and drug features with scaling\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_properties.csv')\n",
    "\n",
    "potential_columns_for_normalisation = []\n",
    "for col in df.columns:\n",
    "    if (df[col].nunique()>2) & (df[col].dtype != \"O\"):\n",
    "        potential_columns_for_normalisation.append(col)\n",
    "\n",
    "columns_for_normalisation = list(set(potential_columns_for_normalisation) - set(norm_response) - set(param1) - set(param2) -set(['Unnamed: 0', 'DRUG_ID', 'COSMIC_ID',]))\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "print(\"Number of drugs for training:\", len(drug_ids))\n",
    "\n",
    "kernels_to_test = [\"linear\", \"sigmoid\", \"rbf\", \"polynomial\", \"additive_chi2\", \"laplacian\"]\n",
    "results = TuneParameters(df, drug_ids, 4, kernels = kernels_to_test, column_not_to_use=column_not_to_use, \n",
    "                         features_to_scale=columns_for_normalisation, scaling = True,\n",
    "                         print_results=False)\n",
    "\n",
    "print(\"Tuned parameters:\")\n",
    "print(results)\n",
    "print(\"\\nBetter presentation:\")\n",
    "for key in results:\n",
    "    print(key,\"\\t\", results[key])\n",
    "\n",
    "best_kernels, compared_means = TrainTestBestParameters(df, drug_ids, 4, kernels = kernels_to_test, \n",
    "                                                       column_not_to_use=column_not_to_use, \n",
    "                                                       best_parameters_dict = results, \n",
    "                                                       features_to_scale=columns_for_normalisation, scaling = True,\n",
    "                                                       print_results=True)\n",
    "print(\"Best Kernels:\", best_kernels)\n",
    "compared_means.to_csv(_FOLDER+\"kernel_learning_4.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import leastsq\n",
    "import scipy.optimize as opt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "from data_preprocessing import FilteringCurves, ShowResponseCurves\n",
    "from fitting_curves import FittingColumn, ShowResponseCurvesWithFitting, compute_r2_score\n",
    "_FOLDER = \"/home/acq18mk/master/results/\"\n",
    "\n",
    "\n",
    "### Coding Part\n",
    "\n",
    "def LeaveOneOutError(model, X, y, metrics = \"mse\"):\n",
    "    errors = []\n",
    "    splitter_loo = LeaveOneOut()\n",
    "#     print(splitter_loo.get_n_splits(X))\n",
    "    \n",
    "    for train_index, test_index in splitter_loo.split(X):\n",
    "        X_train_loo, X_test_loo = X[train_index, :], X[test_index,:]\n",
    "        y_train_loo, y_test_loo = y[train_index], y[test_index]\n",
    "        \n",
    "        model = model.fit(X_train_loo, y_train_loo)\n",
    "        if metrics == \"mse\":\n",
    "            mse = mean_squared_error(y_test_loo, model.predict(X_test_loo))\n",
    "            errors.append(mse)\n",
    "        elif metrics == \"mae\":\n",
    "            mae = mean_absolute_error(y_test_loo, model.predict(X_test_loo))\n",
    "            errors.append(mae)\n",
    "    \n",
    "    return (sum(errors)/ len(errors)) \n",
    "\n",
    "\n",
    "def RunCrossValidation(merged_df, drug_ids, number_coefficients, column_not_to_use =[], param_tested = \"alpha\", param_tested_values = [], alpha=1, solver= \"auto\", print_results=True):\n",
    "    \n",
    "    param1 = [\"param_\" +str(i) for i in range(10)]\n",
    "    param2 = [\"param\" +str(i) for i in range(10)] \n",
    "    norm_response  = [\"norm_cells_\"+str(i) for i in range(10)]\n",
    "    con_columns  = [\"fd_num_\"+str(i) for i in range(10)]\n",
    "\n",
    "    not_X_columns = param1 + param2 + norm_response + con_columns + column_not_to_use\n",
    "    X_columns = set(df.columns) - set(not_X_columns)\n",
    "    \n",
    "    df_errors = pd.DataFrame()\n",
    "\n",
    "    for drug_id in drug_ids:\n",
    "        merged_df_i = merged_df[merged_df[\"DRUG_ID\"]==drug_id]\n",
    "        # merged_df_i has lower shape\n",
    "        np.random.seed(123)\n",
    "        indexes = np.random.permutation(merged_df_i.index)\n",
    "        train_size = int(merged_df_i.shape[0]*0.8)\n",
    "        indexes_train = indexes[:train_size]\n",
    "        X_train = merged_df_i.loc[indexes_train, X_columns].values\n",
    "    \n",
    "        for i in range(number_coefficients):\n",
    "            #check whether each coefficient needs its own parameters\n",
    "            if type(alpha)==dict:\n",
    "                alpha_value = alpha[i+1]\n",
    "            else:\n",
    "                alpha_value = alpha\n",
    "                \n",
    "            if type(solver)==dict:\n",
    "                solver_value = solver[i+1]\n",
    "            else:\n",
    "                solver_value = solver\n",
    "                \n",
    "            y_train = merged_df_i.loc[indexes_train, \"param_\"+str(i+1)].values\n",
    "            \n",
    "            for param in param_tested_values:\n",
    "    \n",
    "                #check whether each coefficient needs its own parameters\n",
    "                if param_tested == \"alpha\":\n",
    "                    model = Ridge(alpha=param, solver= solver_value)\n",
    "                elif param_tested == \"solver\":\n",
    "                    model = Ridge(alpha=alpha_value, solver=param)\n",
    "                    \n",
    "                else:\n",
    "                    print(\"ERROR: Unknown parameters\")\n",
    "                \n",
    "                # mse is more sensitive to different parameters choice\n",
    "                mse = LeaveOneOutError(model, X_train, y_train, metrics=\"mse\")\n",
    "                df_errors.loc[drug_id, \"mse_coef\"+str(i+1)+\" \"+str(param)] = mse\n",
    "\n",
    "        \n",
    "    best_values = {}\n",
    "    for coef in range(number_coefficients):\n",
    "        df_results = df_errors[[\"mse_coef\"+str(coef+1)+\" \"+str(param) for param in param_tested_values]].describe().loc[[\"mean\", \"min\",\"max\"], :]\n",
    "        if param_tested != \"solver\":\n",
    "            best_param = np.float32(df_results.loc[\"mean\",:].idxmin().split(\" \")[1])\n",
    "        else:\n",
    "            best_param = df_results.loc[\"mean\",:].idxmin().split(\" \")[1]\n",
    "        best_values[coef+1] = best_param\n",
    "        if print_results:\n",
    "            print(df_results)\n",
    "            if type(best_param) != str:\n",
    "                print(\"Coefficient %d: ,  Best %s: %.5f\" % (coef+1, param_tested, best_param))\n",
    "            else:\n",
    "                print(\"Coefficient %d: ,  Best %s: %s\" % (coef+1, param_tested, best_param))\n",
    "        \n",
    "    del df_errors\n",
    "    print(\"\\nBest values for parameter:\", param_tested)\n",
    "    print(best_values)\n",
    "    return best_values\n",
    "\n",
    "def TuneParameters(merged_df, drug_ids, number_coefficients, column_not_to_use =[], \n",
    "                   param_tested_alphas = [], param_tested_solvers = [], print_results=True):\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    start_time = time.time()\n",
    "    best_solver = RunCrossValidation(merged_df, drug_ids, 4, column_not_to_use= column_not_to_use, \n",
    "                                     param_tested = \"solver\", \n",
    "                                     param_tested_values = param_tested_solvers, \n",
    "                                     alpha = 1,\n",
    "                                     print_results=print_results)\n",
    "\n",
    "    results[\"solver\"] = best_solver\n",
    "    print(\"\\n Execution time for tuning solver: %.3f seconds\" % (time.time() - start_time))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    best_alpha = RunCrossValidation(merged_df, drug_ids, 4, column_not_to_use= column_not_to_use, \n",
    "                                    param_tested = \"alpha\", \n",
    "                                    param_tested_values = param_tested_alphas, \n",
    "                                    solver = best_solver,\n",
    "                                    print_results=print_results)\n",
    "            \n",
    "    print(\"\\n Execution time for tuning alpha: %.3f seconds\" % (time.time() - start_time))\n",
    "    results[\"alpha\"] = best_alpha\n",
    "    \n",
    "    \n",
    "\n",
    "    return  results\n",
    "\n",
    "def TestTunedModel(merged_df, drug_ids, number_coefficients, column_not_to_use=[], alpha=1, solver =\"auto\", \n",
    "                     metrics = \"mse\", print_results=True):\n",
    "    \"\"\"Training and testing Kernels with the best found hyperparameters\"\"\"\n",
    "    \n",
    "    param1 = [\"param_\" +str(i) for i in range(10)]\n",
    "    param2 = [\"param\" +str(i) for i in range(10)] \n",
    "    norm_response  = [\"norm_cells_\"+str(i) for i in range(10)]\n",
    "    con_columns  = [\"fd_num_\"+str(i) for i in range(10)]\n",
    "\n",
    "    not_X_columns = param1 + param2 + norm_response + con_columns + column_not_to_use\n",
    "    X_columns = set(df.columns) - set(not_X_columns)\n",
    "    \n",
    "    df_errors_test = pd.DataFrame()\n",
    "\n",
    "    for drug_id in drug_ids:\n",
    "        # merged_df_i has lower shape\n",
    "        merged_df_i = merged_df[merged_df[\"DRUG_ID\"]==drug_id]\n",
    "        \n",
    "        np.random.seed(123)\n",
    "        indexes = np.random.permutation(merged_df_i.index)\n",
    "        train_size = int(merged_df_i.shape[0]*0.8)\n",
    "        indexes_train = indexes[:train_size]\n",
    "        indexes_test= indexes[train_size:]\n",
    "        X_train = merged_df_i.loc[indexes_train, X_columns].values\n",
    "        X_test = merged_df_i.loc[indexes_test, X_columns].values\n",
    "    \n",
    "        for i in range(number_coefficients):\n",
    "#             param = best_param[i+1]\n",
    "            y_train = merged_df_i.loc[indexes_train, \"param_\"+str(i+1)].values\n",
    "            y_test = merged_df_i.loc[indexes_test, \"param_\"+str(i+1)].values\n",
    "            \n",
    "            #check whether each coefficient needs its own parameters\n",
    "            if type(alpha)==dict:\n",
    "                alpha_value = alpha[i+1]\n",
    "            else:\n",
    "                alpha_value = alpha\n",
    "                \n",
    "            if type(solver)==dict:\n",
    "                solver_value = solver[i+1]\n",
    "            else:\n",
    "                solver_value = solver\n",
    "                \n",
    "            lin_reg = Ridge(alpha = alpha_value, solver = solver_value)\n",
    "            lin_reg.fit(X_train, y_train)\n",
    "            y_pred = np.exp(lin_reg.predict(X_test))\n",
    "                                \n",
    "            # mse is more sensitive to different parameters choice\n",
    "            if metrics == \"mse\":\n",
    "                error = mean_squared_error(y_test, y_pred)\n",
    "            elif metrics == \"mae\":\n",
    "                error = mean_absolute_error(y_test, y_pred)\n",
    "            else:\n",
    "                print(\"ERROR: Unknown metrics\")\n",
    "            df_errors_test.loc[drug_id, \"mse_coef\"+str(i+1)] = error\n",
    "    \n",
    "    df_results = df_errors_test.describe().loc[[\"mean\", \"min\",\"max\"], :]\n",
    "    if print_results: \n",
    "        print(df_results)\n",
    "    return df_results\n",
    "\n",
    "### Analytical Part\n",
    "\n",
    "# **Data Preprocessing pipeline:**\n",
    "#     1. filter drug_profiles data \n",
    "#     (123 - three stages of filtration, 23 - two stages of filtration):\n",
    "#         - \"results/filtered_drug_profiles_123\" (less data)\n",
    "#         - \"results/filtered_drug_profiles_23\" (more data)\n",
    "#     2. add drug features to drug data\n",
    "#     - \"data/Drug_Features.csv\" (original data)\n",
    "#     - \"results/drug_features_with_properties2.csv\" (data with pubchem properties)\n",
    "#     3. merged drug_profiles and drug_features\n",
    "# **For goog comparison:**\n",
    "#     filter merged data so that they have only drug with features \n",
    "#     <br>for both data frames (original drug features and with added pubchem features)\n",
    "\n",
    "column_not_to_use = [\"Unnamed: 0\", \"COSMIC_ID\", \"DRUG_ID\", \"Drug_Name\", \"Synonyms\", \"Target\", \"deriv_found\", \"PubChem_ID\",\n",
    "                     \"elements\", \"inchi_key\", \"canonical_smiles\", \"inchi_string\", \"third_target\", \"first_target\", \"molecular_formula\", \"second_target\", \"Target_Pathway\"]\n",
    "\n",
    "### Finding optimal parameters for just drug profiles and cell lines\n",
    "\n",
    "print(\"\\nFinding optimal parameters for just drug profiles and cell lines\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_description.csv').drop([\"Drug_Name\",\"Target_Pathway\"], axis=1)\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "len(drug_ids)\n",
    "\n",
    "param_tested_alphas = [0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 300, 500]\n",
    "param_tested_solvers = [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\"]\n",
    "\n",
    "\n",
    "results = TuneParameters(df, drug_ids, 4, column_not_to_use=column_not_to_use, param_tested_alphas=param_tested_alphas,\n",
    "                         param_tested_solvers = param_tested_solvers, print_results=False)\n",
    "\n",
    "print(TestTunedModel(df, drug_ids, 4, column_not_to_use= column_not_to_use,\n",
    "                                     alpha=results[\"alpha\"],\n",
    "                                     solver = results[\"solver\"],\n",
    "                                    metrics = \"mse\", print_results=False))\n",
    "\n",
    "\n",
    "### Finding optimal parameters for drug profiles, cell lines and drug description\n",
    "\n",
    "print(\"\\nFinding optimal parameters for drug profiles, cell lines and drug description\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_description.csv')\n",
    "\n",
    "# OHE and dumnies columns for Target_Pathway - 21 new columns\n",
    "df = pd.concat([df, pd.get_dummies(df[\"Target_Pathway\"])], axis=1).drop(\"Target_Pathway\", axis=1)\n",
    "\n",
    "column_not_to_use = [\"Unnamed: 0\", \"COSMIC_ID\", \"DRUG_ID\", \"Drug_Name\", \"Synonyms\", \"Target\", \"deriv_found\", \"PubChem_ID\",\n",
    "                     \"elements\", \"inchi_key\", \"canonical_smiles\", \"inchi_string\", \"third_target\", \"first_target\", \"molecular_formula\", \"second_target\", \"Target_Pathway\"]\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "len(drug_ids)\n",
    "\n",
    "param_tested_alphas = [0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 300, 500]\n",
    "param_tested_solvers = [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\"]\n",
    "\n",
    "\n",
    "results = TuneParameters(df, drug_ids, 4, column_not_to_use=column_not_to_use, param_tested_alphas=param_tested_alphas,\n",
    "                         param_tested_solvers = param_tested_solvers, print_results=False)\n",
    "\n",
    "print(TestTunedModel(df, drug_ids, 4, column_not_to_use= column_not_to_use,\n",
    "                                     alpha=results[\"alpha\"],\n",
    "                                     solver = results[\"solver\"],\n",
    "                                    metrics = \"mse\", print_results=False))\n",
    "\n",
    "### Finding optimal parameters for drug profiles, cell lines and drug features\n",
    "\n",
    "print(\"\\nFinding optimal parameters for drug profiles, cell lines and drug features\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_properties.csv')\n",
    "\n",
    "column_not_to_use = [\"Unnamed: 0\", \"COSMIC_ID\", \"DRUG_ID\", \"Drug_Name\", \"Synonyms\", \"Target\", \"deriv_found\", \"PubChem_ID\",\n",
    "                     \"elements\", \"inchi_key\", \"canonical_smiles\", \"inchi_string\", \"third_target\", \"first_target\", \"molecular_formula\", \"second_target\", \"Target_Pathway\"]\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "len(drug_ids)\n",
    "\n",
    "param_tested_alphas = [0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 300, 500]\n",
    "param_tested_solvers = [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\"]\n",
    "\n",
    "\n",
    "results = TuneParameters(df, drug_ids, 4, column_not_to_use=column_not_to_use, param_tested_alphas=param_tested_alphas,\n",
    "                         param_tested_solvers = param_tested_solvers, print_results=False)\n",
    "\n",
    "print(TestTunedModel(df, drug_ids, 4, column_not_to_use= column_not_to_use,\n",
    "                                     alpha=results[\"alpha\"],\n",
    "                                     solver = results[\"solver\"],\n",
    "                                    metrics = \"mse\", print_results=False))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "myspark",
   "language": "python",
   "name": "myspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
