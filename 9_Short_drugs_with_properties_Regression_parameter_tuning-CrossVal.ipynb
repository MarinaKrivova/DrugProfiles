{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import leastsq\n",
    "import scipy.optimize as opt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from data_preprocessing import FilteringCurves, ShowResponseCurves\n",
    "from fitting_curves import FittingColumn, ShowResponseCurvesWithFitting, compute_r2_score\n",
    "# _FOLDER = \"/home/acq18mk/master/results/\"\n",
    "_FOLDER = \"results/\"\n",
    "\n",
    "### Coding Part\n",
    "\n",
    "def LeaveOneOutError(model, X, y, metrics = \"mse\"):\n",
    "    errors = []\n",
    "    splitter_loo = LeaveOneOut()\n",
    "#     print(splitter_loo.get_n_splits(X))\n",
    "    \n",
    "    for train_index, test_index in splitter_loo.split(X):\n",
    "        X_train_loo, X_test_loo = X[train_index, :], X[test_index,:]\n",
    "        y_train_loo, y_test_loo = y[train_index], y[test_index]\n",
    "        \n",
    "        model = model.fit(X_train_loo, y_train_loo)\n",
    "        if metrics == \"mse\":\n",
    "            mse = mean_squared_error(y_test_loo, model.predict(X_test_loo))\n",
    "            errors.append(mse)\n",
    "        elif metrics == \"mae\":\n",
    "            mae = mean_absolute_error(y_test_loo, model.predict(X_test_loo))\n",
    "            errors.append(mae)\n",
    "    \n",
    "    return (sum(errors)/ len(errors)) \n",
    "\n",
    "\n",
    "def RunCrossValidation(merged_df, drug_ids, number_coefficients, column_not_to_use =[], \n",
    "                       param_tested = \"alpha\", param_tested_values = [],\n",
    "                       alpha=1, solver= \"auto\", \n",
    "                       features_to_scale = [], scaling=False,\n",
    "                       print_results=True):\n",
    "    \n",
    "    param1 = [\"param_\" +str(i) for i in range(10)]\n",
    "    param2 = [\"param\" +str(i) for i in range(10)] \n",
    "    norm_response  = [\"norm_cells_\"+str(i) for i in range(10)]\n",
    "    con_columns  = [\"fd_num_\"+str(i) for i in range(10)]\n",
    "\n",
    "    not_X_columns = param1 + param2 + norm_response + con_columns + column_not_to_use\n",
    "    X_columns = set(df.columns) - set(not_X_columns)\n",
    "    \n",
    "    df_errors = pd.DataFrame()\n",
    "\n",
    "    for drug_id in drug_ids:\n",
    "        merged_df_i = merged_df[merged_df[\"DRUG_ID\"]==drug_id]\n",
    "        # merged_df_i has lower shape\n",
    "        np.random.seed(123)\n",
    "        indexes = np.random.permutation(merged_df_i.index)\n",
    "        train_size = int(merged_df_i.shape[0]*0.8)\n",
    "        indexes_train = indexes[:train_size]\n",
    "        \n",
    "        if scaling:\n",
    "            train=merged_df_i.loc[indexes_train, X_columns].copy()\n",
    "            scaler = MinMaxScaler()\n",
    "            train[columns_for_normalisation] = scaler.fit_transform(train[columns_for_normalisation])\n",
    "            X_train = train.values     \n",
    "        else:\n",
    "            X_train = merged_df_i.loc[indexes_train, X_columns].values\n",
    "    \n",
    "        for i in range(number_coefficients):\n",
    "            #check whether each coefficient needs its own parameters\n",
    "            if type(alpha)==dict:\n",
    "                alpha_value = alpha[i+1]\n",
    "            else:\n",
    "                alpha_value = alpha\n",
    "                \n",
    "            if type(solver)==dict:\n",
    "                solver_value = solver[i+1]\n",
    "            else:\n",
    "                solver_value = solver\n",
    "                \n",
    "            y_train = merged_df_i.loc[indexes_train, \"param_\"+str(i+1)].values\n",
    "            \n",
    "            for param in param_tested_values:\n",
    "    \n",
    "                #check whether each coefficient needs its own parameters\n",
    "                if param_tested == \"alpha\":\n",
    "                    model = Ridge(alpha=param, solver= solver_value)\n",
    "                elif param_tested == \"solver\":\n",
    "                    model = Ridge(alpha=alpha_value, solver=param)\n",
    "                    \n",
    "                else:\n",
    "                    print(\"ERROR: Unknown parameters\")\n",
    "                \n",
    "                # mse is more sensitive to different parameters choice\n",
    "                mse = LeaveOneOutError(model, X_train, y_train, metrics=\"mse\")\n",
    "                df_errors.loc[drug_id, \"mse_coef\"+str(i+1)+\" \"+str(param)] = mse\n",
    "\n",
    "        \n",
    "    best_values = {}\n",
    "    for coef in range(number_coefficients):\n",
    "        df_results = df_errors[[\"mse_coef\"+str(coef+1)+\" \"+str(param) for param in param_tested_values]].describe().loc[[\"mean\", \"min\",\"max\"], :]\n",
    "        if param_tested != \"solver\":\n",
    "            best_param = np.float32(df_results.loc[\"mean\",:].idxmin().split(\" \")[1])\n",
    "        else:\n",
    "            best_param = df_results.loc[\"mean\",:].idxmin().split(\" \")[1]\n",
    "        best_values[coef+1] = best_param\n",
    "        if print_results:\n",
    "            print(df_results)\n",
    "            if type(best_param) != str:\n",
    "                print(\"Coefficient %d: ,  Best %s: %.5f\" % (coef+1, param_tested, best_param))\n",
    "            else:\n",
    "                print(\"Coefficient %d: ,  Best %s: %s\" % (coef+1, param_tested, best_param))\n",
    "        \n",
    "    del df_errors\n",
    "    print(\"\\nBest values for parameter:\", param_tested)\n",
    "    print(best_values)\n",
    "    return best_values\n",
    "\n",
    "def TuneParameters(merged_df, drug_ids, number_coefficients, column_not_to_use =[], \n",
    "                   param_tested_alphas = [], param_tested_solvers = [], \n",
    "                   features_to_scale = [], scaling=False,\n",
    "                   print_results=True):\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    start_time = time.time()\n",
    "    best_solver = RunCrossValidation(merged_df, drug_ids, 4, column_not_to_use= column_not_to_use, \n",
    "                                     param_tested = \"solver\", \n",
    "                                     param_tested_values = param_tested_solvers, \n",
    "                                     alpha = 1,\n",
    "                                     features_to_scale = features_to_scale, scaling=True,\n",
    "                                     print_results=print_results)\n",
    "\n",
    "    results[\"solver\"] = best_solver\n",
    "    print(\"\\n Execution time for tuning solver: %.3f seconds\" % (time.time() - start_time))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    best_alpha = RunCrossValidation(merged_df, drug_ids, 4, column_not_to_use= column_not_to_use, \n",
    "                                    param_tested = \"alpha\", \n",
    "                                    param_tested_values = param_tested_alphas, \n",
    "                                    solver = best_solver,\n",
    "                                    features_to_scale = features_to_scale, scaling=True,\n",
    "                                    print_results=print_results)\n",
    "            \n",
    "    print(\"\\n Execution time for tuning alpha: %.3f seconds\" % (time.time() - start_time))\n",
    "    results[\"alpha\"] = best_alpha\n",
    "    \n",
    "    return  results\n",
    "\n",
    "def TestTunedModel(merged_df, drug_ids, number_coefficients, column_not_to_use=[], alpha=1, solver =\"auto\", \n",
    "                     metrics = \"mse\", features_to_scale = [], scaling=False, print_results=True):\n",
    "    \"\"\"Training and testing Kernels with the best found hyperparameters\"\"\"\n",
    "    \n",
    "    param1 = [\"param_\" +str(i) for i in range(10)]\n",
    "    param2 = [\"param\" +str(i) for i in range(10)] \n",
    "    norm_response  = [\"norm_cells_\"+str(i) for i in range(10)]\n",
    "    con_columns  = [\"fd_num_\"+str(i) for i in range(10)]\n",
    "\n",
    "    not_X_columns = param1 + param2 + norm_response + con_columns + column_not_to_use\n",
    "    X_columns = set(df.columns) - set(not_X_columns)\n",
    "    \n",
    "    df_errors_test = pd.DataFrame()\n",
    "\n",
    "    for drug_id in drug_ids:\n",
    "        # merged_df_i has lower shape\n",
    "        merged_df_i = merged_df[merged_df[\"DRUG_ID\"]==drug_id]\n",
    "    \n",
    "        np.random.seed(123)\n",
    "        indexes = np.random.permutation(merged_df_i.index)\n",
    "        train_size = int(merged_df_i.shape[0]*0.8)\n",
    "        indexes_train = indexes[:train_size]\n",
    "        indexes_test = indexes[train_size:]\n",
    "        \n",
    "        if scaling:\n",
    "            train=merged_df_i.loc[indexes_train, X_columns].copy()\n",
    "            test = merged_df_i.loc[indexes_test, X_columns].copy()\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(train[columns_for_normalisation])\n",
    "            train[columns_for_normalisation] = scaler.transform(train[columns_for_normalisation])\n",
    "            test[columns_for_normalisation] = scaler.transform(test[columns_for_normalisation])\n",
    "            X_train = train.values\n",
    "            X_test = test.values \n",
    "        else:\n",
    "            X_train = merged_df_i.loc[indexes_train, X_columns].values\n",
    "            X_test = merged_df_i.loc[indexes_test, X_columns].values\n",
    "    \n",
    "        for i in range(number_coefficients):\n",
    "#             param = best_param[i+1]\n",
    "            y_train = merged_df_i.loc[indexes_train, \"param_\"+str(i+1)].values\n",
    "            y_test = merged_df_i.loc[indexes_test, \"param_\"+str(i+1)].values\n",
    "            \n",
    "            #check whether each coefficient needs its own parameters\n",
    "            if type(alpha)==dict:\n",
    "                alpha_value = alpha[i+1]\n",
    "            else:\n",
    "                alpha_value = alpha\n",
    "                \n",
    "            if type(solver)==dict:\n",
    "                solver_value = solver[i+1]\n",
    "            else:\n",
    "                solver_value = solver\n",
    "                \n",
    "            lin_reg = Ridge(alpha = alpha_value, solver = solver_value)\n",
    "            lin_reg.fit(X_train, y_train)\n",
    "            y_pred = np.exp(lin_reg.predict(X_test))\n",
    "                                \n",
    "            # mse is more sensitive to different parameters choice\n",
    "            if metrics == \"mse\":\n",
    "                error = mean_squared_error(y_test, y_pred)\n",
    "            elif metrics == \"mae\":\n",
    "                error = mean_absolute_error(y_test, y_pred)\n",
    "            else:\n",
    "                print(\"ERROR: Unknown metrics\")\n",
    "            df_errors_test.loc[drug_id, \"mse_coef\"+str(i+1)] = error\n",
    "    \n",
    "    df_results = df_errors_test.describe().loc[[\"mean\", \"min\",\"max\"], :]\n",
    "    if print_results: \n",
    "        print(df_results)\n",
    "    return df_results\n",
    "\n",
    "### Analytical Part\n",
    "\n",
    "# **Data Preprocessing pipeline:**\n",
    "#     1. filter drug_profiles data \n",
    "#     (123 - three stages of filtration, 23 - two stages of filtration):\n",
    "#         - \"results/filtered_drug_profiles_123\" (less data)\n",
    "#         - \"results/filtered_drug_profiles_23\" (more data)\n",
    "#     2. add drug features to drug data\n",
    "#     - \"data/Drug_Features.csv\" (original data)\n",
    "#     - \"results/drug_features_with_properties2.csv\" (data with pubchem properties)\n",
    "#     3. merged drug_profiles and drug_features\n",
    "# **For goog comparison:**\n",
    "#     filter merged data so that they have only drug with features \n",
    "#     <br>for both data frames (original drug features and with added pubchem features)\n",
    "\n",
    "### 1. Finding optimal parameters for just drug profiles and cell lines\n",
    "\n",
    "print(\"\\n1. Finding optimal parameters for just drug profiles and cell lines\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_description.csv').drop([\"Drug_Name\",\"Target_Pathway\"], axis=1)\n",
    "\n",
    "column_not_to_use = [\"Unnamed: 0\", \"COSMIC_ID\", \"DRUG_ID\", \"Drug_Name\", \"Synonyms\", \"Target\", \"deriv_found\", \"PubChem_ID\",\n",
    "                     \"elements\", \"inchi_key\", \"canonical_smiles\", \"inchi_string\", \"third_target\", \"first_target\", \"molecular_formula\", \"second_target\", \"Target_Pathway\"]\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "len(drug_ids)\n",
    "\n",
    "param_tested_alphas = [0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 300, 500]\n",
    "param_tested_solvers = [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\"]\n",
    "\n",
    "\n",
    "results = TuneParameters(df, drug_ids, 4, column_not_to_use=column_not_to_use, \n",
    "                         param_tested_alphas=param_tested_alphas,\n",
    "                         param_tested_solvers = param_tested_solvers, \n",
    "                         print_results=False)\n",
    "\n",
    "df_results = TestTunedModel(df, drug_ids, 4, column_not_to_use= column_not_to_use,\n",
    "                            alpha=results[\"alpha\"], solver = results[\"solver\"],\n",
    "                            metrics = \"mse\", print_results=False)\n",
    "\n",
    "df_results.to_csv(_FOLDER+\"Ridge_1.csv\")\n",
    "print(df_results)\n",
    "\n",
    "### 2. Finding optimal parameters for drug profiles, cell lines and drug description\n",
    "\n",
    "print(\"\\n2. Finding optimal parameters for drug profiles, cell lines and drug description\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_description.csv')\n",
    "\n",
    "# OHE and dumnies columns for Target_Pathway - 21 new columns\n",
    "df = pd.concat([df, pd.get_dummies(df[\"Target_Pathway\"])], axis=1).drop(\"Target_Pathway\", axis=1)\n",
    "\n",
    "column_not_to_use = [\"Unnamed: 0\", \"COSMIC_ID\", \"DRUG_ID\", \"Drug_Name\", \"Synonyms\", \"Target\", \"deriv_found\", \"PubChem_ID\",\n",
    "                     \"elements\", \"inchi_key\", \"canonical_smiles\", \"inchi_string\", \"third_target\", \"first_target\", \"molecular_formula\", \"second_target\", \"Target_Pathway\"]\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "len(drug_ids)\n",
    "\n",
    "param_tested_alphas = [0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 300, 500]\n",
    "param_tested_solvers = [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\"]\n",
    "\n",
    "\n",
    "results = TuneParameters(df, drug_ids, 4, column_not_to_use=column_not_to_use, \n",
    "                         param_tested_alphas=param_tested_alphas,\n",
    "                         param_tested_solvers = param_tested_solvers, print_results=False)\n",
    "\n",
    "df_results = TestTunedModel(df, drug_ids, 4, column_not_to_use= column_not_to_use,\n",
    "                            alpha=results[\"alpha\"], solver = results[\"solver\"],\n",
    "                            metrics = \"mse\", print_results=False)\n",
    "\n",
    "df_results.to_csv(_FOLDER+\"Ridge_2.csv\")\n",
    "print(df_results)\n",
    "\n",
    "### 3. Finding optimal parameters for drug profiles, cell lines and drug features\n",
    "\n",
    "print(\"\\n3. Finding optimal parameters for drug profiles, cell lines and drug features\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_description.csv')\n",
    "\n",
    "column_not_to_use = [\"Unnamed: 0\", \"COSMIC_ID\", \"DRUG_ID\", \"Drug_Name\", \"Synonyms\", \"Target\", \"deriv_found\", \"PubChem_ID\",\n",
    "                     \"elements\", \"inchi_key\", \"canonical_smiles\", \"inchi_string\", \"third_target\", \"first_target\", \"molecular_formula\", \"second_target\", \"Target_Pathway\"]\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "len(drug_ids)\n",
    "\n",
    "param_tested_alphas = [0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 300, 500]\n",
    "param_tested_solvers = [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\"]\n",
    "\n",
    "\n",
    "results = TuneParameters(df, drug_ids, 4, column_not_to_use=column_not_to_use, \n",
    "                         param_tested_alphas=param_tested_alphas,\n",
    "                         param_tested_solvers = param_tested_solvers, print_results=False)\n",
    "\n",
    "df_results = TestTunedModel(df, drug_ids, 4, column_not_to_use= column_not_to_use,\n",
    "                            alpha=results[\"alpha\"], solver = results[\"solver\"],\n",
    "                            metrics = \"mse\", print_results=False)\n",
    "\n",
    "df_results.to_csv(_FOLDER+\"Ridge_3.csv\")\n",
    "print(df_results)\n",
    "\n",
    "\n",
    "### 4. Finding optimal parameters for drug profiles, cell lines and drug features with SCALING\n",
    "\n",
    "print(\"\\n4. Finding optimal parameters for drug profiles, cell lines and drug features with scaling\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_properties.csv')\n",
    "\n",
    "param1 = [\"param_\" +str(i) for i in range(10)]\n",
    "param2 = [\"param\" +str(i) for i in range(10)] \n",
    "norm_response  = [\"norm_cells_\"+str(i) for i in range(10)]\n",
    "con_columns  = [\"fd_num_\"+str(i) for i in range(10)]\n",
    "\n",
    "potential_columns_for_normalisation = []\n",
    "for col in df.columns:\n",
    "    if (df[col].nunique()>2) & (df[col].dtype != \"O\"):\n",
    "        potential_columns_for_normalisation.append(col)\n",
    "\n",
    "columns_for_normalisation = list(set(potential_columns_for_normalisation) - set(norm_response) - set(param1) - set(param2) -set(['Unnamed: 0', 'DRUG_ID', 'COSMIC_ID',]))\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "print(\"Number of drugs for training:\", len(drug_ids))\n",
    "param_tested_alphas = [0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 300, 500]\n",
    "param_tested_solvers = [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\"]\n",
    "\n",
    "\n",
    "results = TuneParameters(df, drug_ids, 4, column_not_to_use=column_not_to_use, \n",
    "                         param_tested_alphas=param_tested_alphas,\n",
    "                         param_tested_solvers = param_tested_solvers, \n",
    "                         features_to_scale=columns_for_normalisation, scaling= True,\n",
    "                         print_results=False)\n",
    "\n",
    "df_results = TestTunedModel(df, drug_ids, 4, column_not_to_use= column_not_to_use,\n",
    "                            alpha=results[\"alpha\"], solver = results[\"solver\"], metrics = \"mse\", \n",
    "                            features_to_scale=columns_for_normalisation, scaling= True,\n",
    "                            print_results=False)\n",
    "\n",
    "df_results.to_csv(_FOLDER+\"Ridge_4.csv\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import leastsq\n",
    "import scipy.optimize as opt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "from data_preprocessing import FilteringCurves, ShowResponseCurves\n",
    "from fitting_curves import FittingColumn, ShowResponseCurvesWithFitting, compute_r2_score\n",
    "_FOLDER = \"/home/acq18mk/master/results/\"\n",
    "#_FOLDER = \"results/\"\n",
    "\n",
    "### Coding Part\n",
    "\n",
    "def LeaveOneOutError(model, X, y, metrics = \"mse\"):\n",
    "    errors = []\n",
    "    splitter_loo = LeaveOneOut()\n",
    "#     print(splitter_loo.get_n_splits(X))\n",
    "    \n",
    "    for train_index, test_index in splitter_loo.split(X):\n",
    "        X_train_loo, X_test_loo = X[train_index, :], X[test_index,:]\n",
    "        y_train_loo, y_test_loo = y[train_index], y[test_index]\n",
    "        \n",
    "        model = model.fit(X_train_loo, y_train_loo)\n",
    "        if metrics == \"mse\":\n",
    "            mse = mean_squared_error(y_test_loo, model.predict(X_test_loo))\n",
    "            errors.append(mse)\n",
    "        elif metrics == \"mae\":\n",
    "            mae = mean_absolute_error(y_test_loo, model.predict(X_test_loo))\n",
    "            errors.append(mae)\n",
    "    \n",
    "    return (sum(errors)/ len(errors)) \n",
    "\n",
    "\n",
    "def TuneParametersLasso(merged_df, drug_ids, number_coefficients, column_not_to_use =[], \n",
    "                        param_tested = \"alpha\", param_tested_values = [], \n",
    "                        features_to_scale = [], scaling=False,\n",
    "                        print_results=True):\n",
    "    \n",
    "    param1 = [\"param_\" +str(i) for i in range(10)]\n",
    "    param2 = [\"param\" +str(i) for i in range(10)] \n",
    "    norm_response  = [\"norm_cells_\"+str(i) for i in range(10)]\n",
    "    con_columns  = [\"fd_num_\"+str(i) for i in range(10)]\n",
    "\n",
    "    not_X_columns = param1 + param2 + norm_response + con_columns + column_not_to_use\n",
    "    X_columns = set(df.columns) - set(not_X_columns)\n",
    "    \n",
    "    df_errors = pd.DataFrame()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for drug_id in drug_ids:\n",
    "        merged_df_i = merged_df[merged_df[\"DRUG_ID\"]==drug_id]\n",
    "        # merged_df_i has lower shape\n",
    "        np.random.seed(123)\n",
    "        indexes = np.random.permutation(merged_df_i.index)\n",
    "        train_size = int(merged_df_i.shape[0]*0.8)\n",
    "        indexes_train = indexes[:train_size]\n",
    "        if scaling:\n",
    "            train=merged_df_i.loc[indexes_train, X_columns].copy()\n",
    "            scaler = MinMaxScaler()\n",
    "            train[columns_for_normalisation] = scaler.fit_transform(train[columns_for_normalisation])\n",
    "            X_train = train.values     \n",
    "        else:\n",
    "            X_train = merged_df_i.loc[indexes_train, X_columns].values\n",
    "    \n",
    "        for i in range(number_coefficients):\n",
    "            y_train = merged_df_i.loc[indexes_train, \"param_\"+str(i+1)].values\n",
    "            \n",
    "            for param in param_tested_values:\n",
    "                model = Lasso(alpha=param)\n",
    "                    # mse is more sensitive to different parameters choice\n",
    "                metrics = \"mse\"\n",
    "                mse = LeaveOneOutError(model, X_train, y_train, metrics=metrics)\n",
    "                df_errors.loc[drug_id, metrics+\"_coef\"+str(i+1)+\" \"+str(param)] = mse\n",
    "\n",
    "        \n",
    "    best_values = {}\n",
    "    for coef in range(number_coefficients):\n",
    "        df_results = df_errors[[metrics+\"_coef\"+str(coef+1)+\" \"+str(param) for param in param_tested_values]].describe().loc[[\"mean\", \"min\",\"max\"], :]\n",
    "        best_param = np.float32(df_results.loc[\"mean\",:].idxmin().split(\" \")[1])\n",
    "        best_values[coef+1] = best_param\n",
    "        if print_results:\n",
    "            print(df_results)\n",
    "            print(\"Coefficient %d: ,  Best %s: %.5f\" % (coef+1, param_tested, best_param))\n",
    "        \n",
    "    del df_errors\n",
    "    print(\"\\nBest values for parameter:\", param_tested)\n",
    "    print(best_values)\n",
    "    print(\"\\n Execution time for tuning alpha: %.3f seconds\" % (time.time() - start_time))\n",
    "    return best_values\n",
    "\n",
    "\n",
    "def TestTunedModelLasso(merged_df, drug_ids, number_coefficients, train_ratio=0.8, column_not_to_use=[], alpha=1, \n",
    "                     metrics = \"mse\", features_to_scale = [], scaling=False, file_name = \"\", print_results=True):\n",
    "    \"\"\"Training and testing Kernels with the best found hyperparameters\"\"\"\n",
    "    \n",
    "    param1 = [\"param_\" +str(i) for i in range(10)]\n",
    "    param2 = [\"param\" +str(i) for i in range(10)] \n",
    "    norm_response  = [\"norm_cells_\"+str(i) for i in range(10)]\n",
    "    con_columns  = [\"fd_num_\"+str(i) for i in range(10)]\n",
    "\n",
    "    not_X_columns = param1 + param2 + norm_response + con_columns + column_not_to_use\n",
    "    X_columns = set(df.columns) - set(not_X_columns)\n",
    "    print(len(X_columns))\n",
    "    df_errors_test = pd.DataFrame()\n",
    "\n",
    "    for drug_id in drug_ids:\n",
    "        # merged_df_i has lower shape\n",
    "        merged_df_i = merged_df[merged_df[\"DRUG_ID\"]==drug_id]\n",
    "        \n",
    "        np.random.seed(123)\n",
    "        indexes = np.random.permutation(merged_df_i.index)\n",
    "        train_size = int(merged_df_i.shape[0]*train_ratio)\n",
    "        indexes_train = indexes[:train_size]\n",
    "        indexes_test= indexes[train_size:]\n",
    "        \n",
    "        if scaling:\n",
    "            train = merged_df_i.loc[indexes_train, X_columns].copy()\n",
    "            test = merged_df_i.loc[indexes_test, X_columns].copy()\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(train[columns_for_normalisation])\n",
    "            train[columns_for_normalisation] = scaler.transform(train[columns_for_normalisation])\n",
    "            X_train = train.values  \n",
    "            test[columns_for_normalisation] = scaler.transform(test[columns_for_normalisation])\n",
    "            X_test = test.values\n",
    "        else:\n",
    "            X_train = merged_df_i.loc[indexes_train, X_columns].values\n",
    "            X_test = merged_df_i.loc[indexes_test, X_columns].values\n",
    "    \n",
    "        for i in range(number_coefficients):\n",
    "#             param = best_param[i+1]\n",
    "            y_train = merged_df_i.loc[indexes_train, \"param_\"+str(i+1)].values\n",
    "            y_test = merged_df_i.loc[indexes_test, \"param_\"+str(i+1)].values\n",
    "            \n",
    "            #check whether each coefficient needs its own parameters\n",
    "            if type(alpha)==dict:\n",
    "                alpha_value = alpha[i+1]\n",
    "            else:\n",
    "                alpha_value = alpha\n",
    "                \n",
    "            lin_reg = Lasso(alpha = alpha_value)\n",
    "            lin_reg.fit(X_train, y_train)\n",
    "            \n",
    "            feature_importance = pd.DataFrame(index=X_columns)\n",
    "            feature_importance[\"coef_\"+str(i+1)+\"_\"+str(drug_id)]=lin_reg.coef_\n",
    "            \n",
    "            y_pred = np.exp(lin_reg.predict(X_test))\n",
    "                                \n",
    "            # mse is more sensitive to different parameters choice\n",
    "            if metrics == \"mse\":\n",
    "                error = mean_squared_error(y_test, y_pred)\n",
    "            elif metrics == \"mae\":\n",
    "                error = mean_absolute_error(y_test, y_pred)\n",
    "            else:\n",
    "                print(\"ERROR: Unknown metrics\")\n",
    "            df_errors_test.loc[drug_id, \"mse_coef\"+str(i+1)] = error\n",
    "            \n",
    "#     feature_importance.to_csv(_FOLDER+\"Lasso_fetures_importance_by_drug\"+file_name+\".csv\")\n",
    "    df_results = df_errors_test.describe().loc[[\"mean\", \"min\",\"max\"], :]\n",
    "    if print_results: \n",
    "        print(df_results)\n",
    "    return df_results\n",
    "\n",
    "### Analytical Part\n",
    "\n",
    "# **Data Preprocessing pipeline:**\n",
    "#     1. filter drug_profiles data \n",
    "#     (123 - three stages of filtration, 23 - two stages of filtration):\n",
    "#         - \"results/filtered_drug_profiles_123\" (less data)\n",
    "#         - \"results/filtered_drug_profiles_23\" (more data)\n",
    "#     2. add drug features to drug data\n",
    "#     - \"data/Drug_Features.csv\" (original data)\n",
    "#     - \"results/drug_features_with_properties2.csv\" (data with pubchem properties)\n",
    "#     3. merged drug_profiles and drug_features\n",
    "# **For goog comparison:**\n",
    "#     filter merged data so that they have only drug with features \n",
    "#     <br>for both data frames (original drug features and with added pubchem features)\n",
    "\n",
    "### 1. Finding optimal parameters for just drug profiles and cell lines\n",
    "\n",
    "print(\"\\n1. Finding optimal parameters for just drug profiles and cell lines\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_description.csv').drop([\"Drug_Name\",\"Target_Pathway\"], axis=1)\n",
    "\n",
    "column_not_to_use = [\"Unnamed: 0\", \"COSMIC_ID\", \"DRUG_ID\", \"Drug_Name\", \"Synonyms\", \"Target\", \"deriv_found\", \"PubChem_ID\",\n",
    "                     \"elements\", \"inchi_key\", \"canonical_smiles\", \"inchi_string\", \"third_target\", \"first_target\", \"molecular_formula\", \"second_target\", \"Target_Pathway\"]\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "len(drug_ids)\n",
    "\n",
    "param_tested_alphas = [0, 0.001, 0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 300, 500]\n",
    "\n",
    "results = TuneParametersLasso(df, drug_ids, 4, column_not_to_use=column_not_to_use, \n",
    "                       param_tested = \"alpha\", param_tested_values = param_tested_alphas, \n",
    "                       print_results=True)\n",
    "\n",
    "df_results = TestTunedModelLasso(df, drug_ids, 4, column_not_to_use= column_not_to_use,\n",
    "                    alpha=results, metrics = \"mse\", print_results=False)\n",
    "df_results.to_csv(_FOLDER+\"Lasso_1.csv\")\n",
    "\n",
    "### 2. Finding optimal parameters for drug profiles, cell lines and drug description\n",
    "\n",
    "print(\"\\n2. Finding optimal parameters for drug profiles, cell lines and drug description\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_description.csv')\n",
    "\n",
    "# OHE and dumnies columns for Target_Pathway - 21 new columns\n",
    "df = pd.concat([df, pd.get_dummies(df[\"Target_Pathway\"])], axis=1).drop(\"Target_Pathway\", axis=1)\n",
    "\n",
    "column_not_to_use = [\"Unnamed: 0\", \"COSMIC_ID\", \"DRUG_ID\", \"Drug_Name\", \"Synonyms\", \"Target\", \"deriv_found\", \"PubChem_ID\",\n",
    "                     \"elements\", \"inchi_key\", \"canonical_smiles\", \"inchi_string\", \"third_target\", \"first_target\", \"molecular_formula\", \"second_target\", \"Target_Pathway\"]\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "len(drug_ids)\n",
    "\n",
    "param_tested_alphas = [0, 0.001, 0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 300, 500]\n",
    "\n",
    "results = TuneParametersLasso(df, drug_ids, 4, column_not_to_use=column_not_to_use, \n",
    "                       param_tested = \"alpha\", param_tested_values = param_tested_alphas, \n",
    "                       print_results=True)\n",
    "\n",
    "df_results = TestTunedModelLasso(df, drug_ids, 4, column_not_to_use= column_not_to_use,\n",
    "                    alpha=results, metrics = \"mse\", print_results=False)\n",
    "df_results.to_csv(_FOLDER+\"Lasso_2.csv\")\n",
    "\n",
    "### 3. Finding optimal parameters for drug profiles, cell lines and drug features\n",
    "\n",
    "print(\"\\n3. Finding optimal parameters for drug profiles, cell lines and drug features\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_description.csv')\n",
    "\n",
    "column_not_to_use = [\"Unnamed: 0\", \"COSMIC_ID\", \"DRUG_ID\", \"Drug_Name\", \"Synonyms\", \"Target\", \"deriv_found\", \"PubChem_ID\",\n",
    "                     \"elements\", \"inchi_key\", \"canonical_smiles\", \"inchi_string\", \"third_target\", \"first_target\", \"molecular_formula\", \"second_target\", \"Target_Pathway\"]\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "len(drug_ids)\n",
    "\n",
    "param_tested_alphas = [0, 0.001, 0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 300, 500]\n",
    "\n",
    "results = TuneParametersLasso(df, drug_ids, 4, column_not_to_use=column_not_to_use, \n",
    "                       param_tested = \"alpha\", param_tested_values = param_tested_alphas, \n",
    "                       print_results=True)\n",
    "\n",
    "df_results = TestTunedModelLasso(df, drug_ids, 4, column_not_to_use= column_not_to_use,\n",
    "                    alpha=results, metrics = \"mse\", print_results=False)\n",
    "df_results.to_csv(_FOLDER+\"Lasso_3.csv\")\n",
    "\n",
    "### 4. Finding optimal parameters for drug profiles, cell lines and drug features with SCALING\n",
    "\n",
    "print(\"\\n4. Finding optimal parameters for drug profiles, cell lines and drug features with scaling\\n\")\n",
    "df = pd.read_csv(_FOLDER+'merged_fitted_sigmoid4_123_with_drugs_properties.csv')\n",
    "\n",
    "param1 = [\"param_\" +str(i) for i in range(10)]\n",
    "param2 = [\"param\" +str(i) for i in range(10)] \n",
    "norm_response  = [\"norm_cells_\"+str(i) for i in range(10)]\n",
    "con_columns  = [\"fd_num_\"+str(i) for i in range(10)]\n",
    "\n",
    "potential_columns_for_normalisation = []\n",
    "for col in df.columns:\n",
    "    if (df[col].nunique()>2) & (df[col].dtype != \"O\"):\n",
    "        potential_columns_for_normalisation.append(col)\n",
    "\n",
    "columns_for_normalisation = list(set(potential_columns_for_normalisation) - set(norm_response) - set(param1) - set(param2) -set(['Unnamed: 0', 'DRUG_ID', 'COSMIC_ID',]))\n",
    "\n",
    "gr = df.groupby([\"DRUG_ID\"])[\"COSMIC_ID\"].count()\n",
    "drug_ids = list(gr[gr > 50].index)\n",
    "print(\"Number of drugs for training:\", len(drug_ids))\n",
    "\n",
    "param_tested_alphas = [0, 0.001, 0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 300, 500]\n",
    "\n",
    "results = TuneParametersLasso(df, drug_ids, 4, column_not_to_use=column_not_to_use, \n",
    "                              param_tested = \"alpha\", param_tested_values = param_tested_alphas, \n",
    "                              features_to_scale=columns_for_normalisation, scaling= True,\n",
    "                              print_results=True)\n",
    "\n",
    "df_results= TestTunedModelLasso(df, drug_ids, 4, column_not_to_use= column_not_to_use,\n",
    "                    alpha=results, features_to_scale=columns_for_normalisation, scaling= True,\n",
    "                    metrics = \"mse\", file_name=\"scaled\", print_results=False)\n",
    " \n",
    "df_results.to_csv(_FOLDER+\"Lasso_4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "myspark",
   "language": "python",
   "name": "myspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
