{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "### Average sigmoid\n",
    "\n",
    "# Main idea: get the DataFrame:\n",
    "#         'DRUG_ID', 'COSMIC_ID', 'Drug_Name', x1 = conc_1, y1 = response_norm_1\n",
    "#         'DRUG_ID', 'COSMIC_ID', 'Drug_Name', x2, y2\n",
    "#         ....\n",
    "#         'DRUG_ID', 'COSMIC_ID', 'Drug_Name', x10, y10\n",
    "# Train non-linear regression (of sigmoid type) to obtain a unified/\"average\" functional dependence between x and y\n",
    "\n",
    "# So, the first step is to split and concat the new dataset\n",
    "\n",
    "train_123 = pd.read_csv(\"results/train08_merged_fitted_sigmoid4_123_with_drugs_properties.csv\").drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "test_123 = pd.read_csv(\"results/test02_merged_fitted_sigmoid4_123_with_drugs_properties.csv\").drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "\n",
    "\n",
    "norm_response  = [\"norm_cells_\"+str(i) for i in range(10)]\n",
    "conc_columns  = [\"fd_num_\"+str(i) for i in range(10)]\n",
    "\n",
    "col_not_to_use = [\"Unnamed: 0\", \"Unnamed: 0.1\", 'DRUG_ID', 'COSMIC_ID', 'Drug_Name', \n",
    "                  \"Synonyms\", \"Target\", \"deriv_found\", \"PubChem_ID\",\"elements\", \"inchi_key\",\n",
    "                  \"canonical_smiles\", \"inchi_string\", \"molecular_formula\",\n",
    "                  \"third_target\", \"first_target\", \"second_target\", \"Target_Pathway\"]\n",
    "\n",
    "columns_to_use = ['DRUG_ID', 'COSMIC_ID', 'Drug_Name'] + list(set(train_123.columns)\n",
    "                                                              -set(norm_response)-set(conc_columns)\n",
    "                                                              -set(col_not_to_use))\n",
    "train = np.zeros([1, len(columns_to_use)+2])\n",
    "for i in range(10):\n",
    "    train = np.vstack((train, train_123[columns_to_use + [\"fd_num_\"+str(i), \"norm_cells_\"+str(i)]].values))\n",
    "\n",
    "train_df_full = pd.DataFrame(data= train[1:,:], columns = columns_to_use + [\"x_conc\", \"y_response\"]).fillna(0)\n",
    "train_df_full[\"x_conc\"]= np.float32(train_df_full[\"x_conc\"])\n",
    "train_df_full[\"y_response\"]= np.float32(train_df_full[\"y_response\"])\n",
    "\n",
    "# test = np.zeros([1, len(columns_to_use)+2])\n",
    "# for i in range(10):\n",
    "#     test = np.vstack((test, test_123[columns_to_use + [\"fd_num_\"+str(i), \"norm_cells_\"+str(i)]].values))\n",
    "\n",
    "# test_df_full = pd.DataFrame(data= test[1:,:], columns = columns_to_use + [\"x_conc\", \"y_response\"]).fillna(0)\n",
    "# test_df_full[\"x_conc\"]= np.float32(test_df_full[\"x_conc\"])\n",
    "# test_df_full[\"y_response\"]= np.float32(test_df_full[\"y_response\"])\n",
    "\n",
    "int_columns = []\n",
    "float_columns = []\n",
    "object_columns = []\n",
    "for col in train_123.columns:\n",
    "    if train_123[col].dtype == \"int64\":\n",
    "        int_columns.append(col)\n",
    "    elif (train_123[col].dtype == \"float64\") | (train_123[col].dtype == \"float32\"):\n",
    "        float_columns.append(col)\n",
    "    else:\n",
    "        object_columns.append(col)\n",
    "\n",
    "float_columns2 = list(set(float_columns) - set(norm_response) - set(conc_columns)-set([\"param_\"+str(i) for i in range(1,5)]))\n",
    "\n",
    "%%time\n",
    "for col in int_columns[4:]:\n",
    "    train_df_full[col] = np.int32(train_df_full[col])\n",
    "#     test_df_full[col] = np.int32(test_df_full[col])\n",
    "for col in float_columns2:\n",
    "    train_df_full[col] = np.float32(train_df_full[col])\n",
    "#     test_df_full[col] = np.float32(test_df_full[col])\n",
    "\n",
    "### Support Vector Regression \n",
    "\n",
    "columns_for_normalisation = ['molecular_weight','rotatable_bond_count', 'h_bond_acceptor_count',\n",
    " 'undefined_atom_stereo_count', 'bond_stereo_count', 'defined_atom_stereo_count',\n",
    " 'complexity', 'atom_stereo_count','covalent_unit_count','2bonds',\n",
    " 'surface_area', 'xlogp', 'heavy_atom_count', \"x_conc\"]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_df_full[columns_for_normalisation])\n",
    "train_df_full[columns_for_normalisation] = scaler.transform(train_df_full[columns_for_normalisation])\n",
    "\n",
    "X_columns = train_df_full.columns[3:-1]\n",
    "X = train_df_full[X_columns].values\n",
    "y = train_df_full[\"y_response\"].values  \n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], \n",
    "                                'gamma': [1e-3, 1e-4, 1e-5], \n",
    "                                'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['sigmoid'], \n",
    "                              'gamma': [1e-3, 1e-4, 1e-5], 'C': [1, 10, 100, 1000], \n",
    "                              \"epsilon\": [0.001, 0.01, 0.1, 1]},\n",
    "                    {'kernel': ['linear'], \n",
    "                               'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "model_search = GridSearchCV(SVR(), tuned_parameters, scoring=\"neg_mean_absolute_error\")\n",
    "model_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters set found on development set:\\n\")\n",
    "print(model_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import SCORERS\n",
    "# SCORERS.keys()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "myspark",
   "language": "python",
   "name": "myspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
